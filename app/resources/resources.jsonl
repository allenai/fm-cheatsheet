{"Name": "BigBench", "Description": "A collaborative benchmark of 100s of tasks, probing LLMs on a wide array of unique capabilities.", "Modalities": ["Text"], "Categories": ["Model Evaluation: Capabilities"], "Date": "6-2022", "Primary Link": "GitHub", "Paper Link": "https://arxiv.org/abs/2206.04615", "Website Link": "", "GitHub Link": "https://github.com/google/BIG-bench", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "BigBench Hard", "Description": "A challenging subset of 23 BigBench tasks where at time of release models did not outperform annotator performance.", "Modalities": ["Text"], "Categories": ["Model Evaluation: Capabilities"], "Date": "10-2022", "Primary Link": "GitHub", "Paper Link": "https://arxiv.org/abs/2210.09261", "Website Link": "", "GitHub Link": "https://github.com/suzgunmirac/BIG-Bench-Hard", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "BigCode Evaluation Harness", "Description": "A framework for the evaluation of code generation models, compiling many evaluation sets.", "Modalities": ["Text"], "Categories": ["Model Evaluation: Capabilities"], "Date": "Frequently Updated", "Primary Link": "GitHub", "Paper Link": "", "Website Link": "", "GitHub Link": "https://github.com/bigcode-project/bigcode-evaluation-harness/tree/main", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "CLIP benchmark", "Description": "Image classification, retrieval and captioning", "Modalities": ["Text", "Vision"], "Categories": ["Model Evaluation: Capabilities"], "Date": "4-2022", "Primary Link": "GitHub", "Paper Link": "", "Website Link": "", "GitHub Link": "https://github.com/LAION-AI/CLIP_benchmark", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "DataComp eval suite", "Description": "38 image classification and retrieval downstream tasks", "Modalities": ["Text", "Vision"], "Categories": ["Model Evaluation: Capabilities"], "Date": "4-2023", "Primary Link": "GitHub", "Paper Link": "https://arxiv.org/abs/2304.14108", "Website Link": "https://www.datacomp.ai/", "GitHub Link": "https://github.com/mlfoundations/datacomp#evaluation", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "HEIM", "Description": "A large suite of text-to-image evaluations. Useful for thorough capability analysis of these model types.", "Modalities": ["Text", "Vision"], "Categories": ["Model Evaluation: Capabilities"], "Date": "11-2023", "Primary Link": "Webpage", "Paper Link": "", "Website Link": "https://crfm.stanford.edu/heim/v1.1.0/", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "HELM classic", "Description": "A large suite of benchmarks and metric types, to holistically evaluate many model qualities aside from performance on general tasks. Useful for a thorough comparison against other well known models.", "Modalities": ["Text"], "Categories": ["Model Evaluation: Capabilities"], "Date": "11-2022", "Primary Link": "Webpage", "Paper Link": "https://arxiv.org/abs/2211.09110", "Website Link": "https://crfm.stanford.edu/helm/latest/", "GitHub Link": "https://github.com/stanford-crfm/helm", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Hugging Face Leaderboards Collection", "Description": "A collection of unique leaderboards on Hugging Face for ranking models across modalities and tasks.", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Model Evaluation: Capabilities"], "Date": "Frequently Updated", "Primary Link": "Hugging Face object", "Paper Link": "", "Website Link": "https://huggingface.co/blog?tag=leaderboard", "GitHub Link": "", "HuggingFace Link": "https://huggingface.co/collections/clefourrier/leaderboards-and-benchmarks-64f99d2e11e92ca5568a7cce", "Added By": "Original Authors"}
{"Name": "HumanEvalPack", "Description": "HumanEvalPack is a code evaluation benchmark across 6 languages and 3 tasks, extending OpenAI's HumanEval.", "Modalities": ["Text"], "Categories": ["Model Evaluation: Capabilities"], "Date": "8-2023", "Primary Link": "GitHub", "Paper Link": "https://arxiv.org/abs/2308.07124", "Website Link": "", "GitHub Link": "https://github.com/bigcode-project/octopack", "HuggingFace Link": "https://huggingface.co/datasets/bigcode/humanevalpack", "Added By": "Original Authors"}
{"Name": "Lighteval", "Description": "Small, highly configurable LLM evaluation library, for fast experimentation and iteration.", "Modalities": ["Text"], "Categories": ["Model Evaluation: Capabilities"], "Date": "Frequently Updated", "Primary Link": "GitHub", "Paper Link": "", "Website Link": "", "GitHub Link": "https://github.com/huggingface/lighteval", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "LM Evaluation Harness", "Description": "Orchestration framework for standardizing LM prompted evaluation, supporting hundreds of subtasks.", "Modalities": ["Text"], "Categories": ["Model Evaluation: Capabilities", "Reproducibility"], "Date": "Frequently Updated", "Primary Link": "GitHub", "Paper Link": "", "Website Link": "", "GitHub Link": "https://github.com/EleutherAI/lm-evaluation-harness", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "LMSys Chatbot Arena", "Description": "A leaderboard of models based on Elo ratings where humans or models select their preferred response between two anonymous models. Chatbot Arena, MT-Bench, and 5-shot MMLU are used as benchmarks. This resource provides a general purpose, and GPT-4 biased perspective into model capabilities.", "Modalities": ["Text"], "Categories": ["Model Evaluation: Capabilities"], "Date": "Frequently Updated", "Primary Link": "Hugging Face object", "Paper Link": "https://arxiv.org/abs/2306.05685", "Website Link": "", "GitHub Link": "https://github.com/lm-sys/FastChat/blob/main/docs/dataset_release.md", "HuggingFace Link": "https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard", "Added By": "Original Authors"}
{"Name": "MMBench", "Description": "A joint vision and text benchmark evaluating dozens of capabilities, using curated datasets and ChatGPT in the loop.", "Modalities": ["Text", "Vision"], "Categories": ["Model Evaluation: Capabilities"], "Date": "7-2023", "Primary Link": "GitHub", "Paper Link": "https://arxiv.org/abs/2307.06281", "Website Link": "https://opencompass.org.cn/mmbench", "GitHub Link": "https://github.com/open-compass/MMBench", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "MME", "Description": "An evaluation benchmark for multimodal large language models with 14 manually curated subtasks, to avoid data leakage.", "Modalities": ["Text", "Vision"], "Categories": ["Model Evaluation: Capabilities"], "Date": "6-2023", "Primary Link": "GitHub", "Paper Link": "https://arxiv.org/abs/2306.13394", "Website Link": "", "GitHub Link": "https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models/", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "MTEB", "Description": "The Massive Text Embedding Benchmark measures the quality of embeddings across 58 datasets and 112 languages for tasks related to retrieval, classification, clustering or semantic similarity.", "Modalities": ["Text"], "Categories": ["Model Evaluation: Capabilities"], "Date": "10-2022", "Primary Link": "GitHub", "Paper Link": "https://arxiv.org/abs/2210.07316", "Website Link": "", "GitHub Link": "https://github.com/embeddings-benchmark/mteb", "HuggingFace Link": "https://huggingface.co/spaces/mteb/leaderboard", "Added By": "Original Authors"}
{"Name": "OpenASR Leaderboard", "Description": "An automatic leaderboard ranking and evaluating speech recognition models on common benchmarks.", "Modalities": ["Speech"], "Categories": ["Model Evaluation: Capabilities"], "Date": "Frequently Updated", "Primary Link": "Hugging Face object", "Paper Link": "", "Website Link": "", "GitHub Link": "https://github.com/huggingface/open_asr_leaderboard", "HuggingFace Link": "https://huggingface.co/spaces/hf-audio/open_asr_leaderboard", "Added By": "Original Authors"}
{"Name": "OpenFlamingo eval suite", "Description": "VQA, captioning, classification", "Modalities": ["Text", "Vision"], "Categories": ["Model Evaluation: Capabilities"], "Date": "8-2023", "Primary Link": "GitHub", "Paper Link": "https://arxiv.org/abs/2308.01390", "Website Link": "", "GitHub Link": "https://github.com/mlfoundations/open_flamingo/tree/main/open_flamingo/eval", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Open LLM Leaderboard", "Description": "A popular leaderboard on Hugging Face for ranking open LLMs on their knowledge, reasoning and math capabilities.", "Modalities": ["Text"], "Categories": ["Model Evaluation: Capabilities"], "Date": "Frequently Updated", "Primary Link": "Hugging Face object", "Paper Link": "", "Website Link": "", "GitHub Link": "", "HuggingFace Link": "https://huggingface.co/open-llm-leaderboard", "Added By": "Original Authors"}
{"Name": "SWE Bench", "Description": "SWE-bench is a benchmark for evaluating large language models on real world software issues collected from GitHub. Given a codebase and an issue, a language model is tasked with generating a patch that resolves the described problem.", "Modalities": ["Text"], "Categories": ["Model Evaluation: Capabilities"], "Date": "10-2023", "Primary Link": "Webpage", "Paper Link": "https://arxiv.org/abs/2310.06770", "Website Link": "https://www.swebench.com/", "GitHub Link": "https://github.com/princeton-nlp/SWE-bench", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "The Edinburgh International Accents of English Corpus", "Description": "Benchmark dataset of diverse English varieties for evaluating automatic speech recognition models (typically trained and tested only on US English)", "Modalities": ["Speech"], "Categories": ["Model Evaluation: Capabilities"], "Date": "3-2023", "Primary Link": "Webpage", "Paper Link": "https://arxiv.org/abs/2303.18110", "Website Link": "https://groups.inf.ed.ac.uk/edacc/", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "HELM lite", "Description": "A lightweight subset of capability-centric benchmarks within HELM with comparisons to many prominent open and closed models.", "Modalities": ["Text"], "Categories": ["Model Evaluation: Capabilities"], "Date": "12-2023", "Primary Link": "Webpage", "Paper Link": "https://crfm.stanford.edu/2023/12/19/helm-lite.html", "Website Link": "https://crfm.stanford.edu/helm/lite/latest/#/", "GitHub Link": "https://github.com/stanford-crfm/helm", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "MMMU", "Description": "A benchmark to evaluate joint text and vision models on 11k examples spanning 30 college-level subject domains.", "Modalities": ["Text", "Vision"], "Categories": ["Model Evaluation: Capabilities"], "Date": "11-2023", "Primary Link": "Webpage", "Paper Link": "https://arxiv.org/abs/2311.16502", "Website Link": "https://mmmu-benchmark.github.io/", "GitHub Link": "https://github.com/MMMU-Benchmark/MMMU", "HuggingFace Link": "https://huggingface.co/datasets/MMMU/MMMU", "Added By": "Original Authors"}
{"Name": "Anaconda", "Description": "An environment and dependency management tool.", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Reproducibility"], "Date": "Frequently Updated", "Primary Link": "Webpage", "Paper Link": "", "Website Link": "https://www.anaconda.com/", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Colab Notebooks", "Description": "A tool to execute and share reproducible code snippets.", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Reproducibility"], "Date": "Frequently Updated", "Primary Link": "Webpage", "Paper Link": "", "Website Link": "https://colab.research.google.com/", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Docker", "Description": "An environment and dependency management tool.", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Reproducibility"], "Date": "Frequently Updated", "Primary Link": "Webpage", "Paper Link": "", "Website Link": "https://docker-curriculum.com/", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Jupyter Notebooks", "Description": "A tool to execute and share reproducible code snippets.", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Reproducibility"], "Date": "Frequently Updated", "Primary Link": "Webpage", "Paper Link": "", "Website Link": "https://jupyter.org/", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Semver", "Description": "A widely used protcol for versioning to software, to ensure easy reproducibility.", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Reproducibility"], "Date": "", "Primary Link": "Webpage", "Paper Link": "", "Website Link": "https://semver.org/", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Reforms", "Description": "Reporting Standards for ML-based Science.", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Reproducibility"], "Date": "8-2023", "Primary Link": "Webpage", "Paper Link": "https://arxiv.org/abs/2308.07832", "Website Link": "https://reforms.cs.princeton.edu/", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "A Retrospective Datasheet for BookCorpus", "Description": "A third party datasheet for BookCorpus", "Modalities": ["Text"], "Categories": ["Data Auditing"], "Date": "5-2021", "Primary Link": "Paper", "Paper Link": "https://arxiv.org/abs/2105.05241", "Website Link": "", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Data Provenance Initiative", "Description": "A large scale audit of 2000+ popular datasets in AI.", "Modalities": ["Text"], "Categories": ["Data Auditing"], "Date": "Frequently Updated", "Primary Link": "Paper", "Paper Link": "https://arxiv.org/abs/2310.16787", "Website Link": "https://www.dataprovenance.org/", "GitHub Link": "https://github.com/Data-Provenance-Initiative/Data-Provenance-Collection", "HuggingFace Link": "https://huggingface.co/DataProvenanceInitiative", "Added By": "Original Authors"}
{"Name": "Datasheet for the Pile", "Description": "A datasheet for the Pile", "Modalities": ["Text"], "Categories": ["Data Auditing"], "Date": "1-2022", "Primary Link": "Paper", "Paper Link": "https://arxiv.org/abs/2201.07311", "Website Link": "", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "HaveIBeenTrained", "Description": "A combination search tool / opt out tool for LAION", "Modalities": ["Text", "Vision"], "Categories": ["Data Auditing", "Data Governance"], "Date": "Frequently Updated", "Primary Link": "Webpage", "Paper Link": "", "Website Link": "https://haveibeentrained.com/", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Into the LAIONs Den", "Description": "Auditing hateful content in text-to-vision datasets.", "Modalities": ["Text", "Vision"], "Categories": ["Data Auditing"], "Date": "9-2023", "Primary Link": "Paper", "Paper Link": "https://arxiv.org/abs/2311.03449", "Website Link": "", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Multimodal datasets: misogyny, pornography, and malignant stereotypes", "Description": "Auditing vision datasets for sensitive content.", "Modalities": ["Text", "Vision"], "Categories": ["Data Auditing"], "Date": "10-2021", "Primary Link": "Paper", "Paper Link": "https://arxiv.org/abs/2110.01963", "Website Link": "", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "On Hate Scaling Laws For Data-Swamps", "Description": "Auditing text and vision datasets for systemic biases and hate.", "Modalities": ["Text", "Vision"], "Categories": ["Data Auditing"], "Date": "6-2023", "Primary Link": "Paper", "Paper Link": "https://arxiv.org/abs/2306.13141", "Website Link": "", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Quality at a Glance", "Description": "An audit of allegedly multilingual parallel text corpora.", "Modalities": ["Text"], "Categories": ["Data Auditing"], "Date": "3-2021", "Primary Link": "Paper", "Paper Link": "https://arxiv.org/abs/2103.12028", "Website Link": "", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Training Data Transparency Blog", "Description": "A blog on transparency for training data in AI.", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Data Auditing"], "Date": "12-2023", "Primary Link": "Webpage", "Paper Link": "", "Website Link": "https://huggingface.co/blog/yjernite/data-transparency", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Data Selection via Importance Resampling (DSIR)", "Description": "A tool for selecting data with a similar distribution to a target dataset", "Modalities": ["Text"], "Categories": ["Data Cleaning, Filtering, & Mixing"], "Date": "12-2023", "Primary Link": "Paper", "Paper Link": "https://arxiv.org/abs/2302.03169", "Website Link": "", "GitHub Link": "https://github.com/p-lambda/dsir", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "DataComp filtering", "Description": "Various quality filters", "Modalities": ["Text", "Vision"], "Categories": ["Data Cleaning, Filtering, & Mixing"], "Date": "4-2023", "Primary Link": "Webpage", "Paper Link": "https://arxiv.org/abs/2304.14108", "Website Link": "https://www.datacomp.ai/", "GitHub Link": "https://github.com/mlfoundations/datacomp/tree/main#baselines", "HuggingFace Link": "https://huggingface.co/datasets/mlfoundations/datacomp_1b", "Added By": "Original Authors"}
{"Name": "DataComp pre-filtering", "Description": "NSFW detection, dedup with eval datasets", "Modalities": ["Text", "Vision"], "Categories": ["Data Cleaning, Filtering, & Mixing"], "Date": "4-2023", "Primary Link": "Webpage", "Paper Link": "https://arxiv.org/abs/2304.14108", "Website Link": "https://www.datacomp.ai/", "GitHub Link": "https://github.com/mlfoundations/dataset2metadata", "HuggingFace Link": "https://huggingface.co/datasets/mlfoundations/datacomp_1b", "Added By": "Original Authors"}
{"Name": "Detoxify", "Description": "A python library designed to identify toxic language in comments. Functions in seven languages: English, Italian, French, Russian, Portuguese, Spanish, Turking.", "Modalities": ["Text"], "Categories": ["Data Cleaning, Filtering, & Mixing"], "Date": "", "Primary Link": "GitHub", "Paper Link": "", "Website Link": "", "GitHub Link": "https://github.com/unitaryai/detoxify", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Dolma's Toolkit", "Description": "A Python framework for defining Taggers that identify non-language text, language ID, PII, toxic text, and \"quality\" text. Includes reimplementation of heuristics used by Gopher and C4 for non-natural language.", "Modalities": ["Text"], "Categories": ["Data Cleaning, Filtering, & Mixing"], "Date": "8-2023", "Primary Link": "Hugging Face object", "Paper Link": "", "Website Link": "", "GitHub Link": "https://github.com/allenai/dolma", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "DoReMi", "Description": "A github repository for Domain Reweighting with Minimax Optimization", "Modalities": ["Text"], "Categories": ["Data Cleaning, Filtering, & Mixing"], "Date": "5-2023", "Primary Link": "Paper", "Paper Link": "https://arxiv.org/abs/2305.10429", "Website Link": "", "GitHub Link": "https://github.com/sangmichaelxie/doremi", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "fastText language classifier", "Description": "A tool for classifying the language of text", "Modalities": ["Text"], "Categories": ["Data Cleaning, Filtering, & Mixing"], "Date": "5-2023", "Primary Link": "Hugging Face object", "Paper Link": "", "Website Link": "", "GitHub Link": "", "HuggingFace Link": "https://huggingface.co/facebook/fasttext-language-identification", "Added By": "Original Authors"}
{"Name": "FUN-LangID", "Description": "Frequently Used N-grams Language ID model, a character 4-gram model trained to recognize up to 1633 languages.", "Modalities": ["Text"], "Categories": ["Data Cleaning, Filtering, & Mixing"], "Date": "9-2023", "Primary Link": "GitHub", "Paper Link": "", "Website Link": "", "GitHub Link": "https://github.com/google-research/url-nlp/tree/main/fun-langid", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "GlotLID", "Description": "A model for identifying languages, with support for more than 1600 languages.", "Modalities": ["Text"], "Categories": ["Data Cleaning, Filtering, & Mixing"], "Date": "", "Primary Link": "GitHub", "Paper Link": "https://arxiv.org/abs/2310.16248", "Website Link": "", "GitHub Link": "https://github.com/cisnlp/GlotLID", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Langdetect", "Description": "A tool to predict the language of text, used to filter out/in data from the desired languages", "Modalities": ["Text"], "Categories": ["Data Cleaning, Filtering, & Mixing"], "Date": "5-2021", "Primary Link": "GitHub", "Paper Link": "", "Website Link": "https://pypi.org/project/langdetect/", "GitHub Link": "https://github.com/Mimino666/langdetect", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Lilac", "Description": "A python package for better understanding your data. Includes keyword and semantic search, as well as detection for PII, duplicates, and language.", "Modalities": ["Text"], "Categories": ["Data Cleaning, Filtering, & Mixing"], "Date": "9-2023", "Primary Link": "GitHub", "Paper Link": "", "Website Link": "https://www.lilacml.com/", "GitHub Link": "https://github.com/lilacai/lilac", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Online Data Mixing", "Description": "A github repository for efficient online data mixing", "Modalities": ["Text"], "Categories": ["Data Cleaning, Filtering, & Mixing"], "Date": "12-2023", "Primary Link": "Paper", "Paper Link": "https://arxiv.org/abs/2312.02406", "Website Link": "", "GitHub Link": "https://github.com/alon-albalak/online-data-mixing", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "OpenLID", "Description": "A model (and data used to train the model) for identifying 200+ languages.", "Modalities": ["Text"], "Categories": ["Data Cleaning, Filtering, & Mixing"], "Date": "", "Primary Link": "GitHub", "Paper Link": "https://arxiv.org/abs/2305.13820", "Website Link": "", "GitHub Link": "https://github.com/laurieburchell/open-lid-dataset", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Roots data cleaning pipeline", "Description": "A pipeline for processing and improving quality of crowdsourced datasets", "Modalities": ["Text"], "Categories": ["Data Cleaning, Filtering, & Mixing"], "Date": "10-2022", "Primary Link": "GitHub", "Paper Link": "", "Website Link": "", "GitHub Link": "https://github.com/bigscience-workshop/data-preparation/tree/main/preprocessing/training/01a_catalogue_cleaning_and_filtering", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "SpeechBrain’s Spoken language ID model", "Description": "Pre-trained spoken language identification model trained on VoxLingua107, dataset of audio sourced from YouTube for 107 languages", "Modalities": ["Speech"], "Categories": ["Data Cleaning, Filtering, & Mixing"], "Date": "6-2021", "Primary Link": "Hugging Face object", "Paper Link": "https://arxiv.org/abs/2106.04624", "Website Link": "", "GitHub Link": "", "HuggingFace Link": "https://huggingface.co/speechbrain/lang-id-voxlingua107-ecapa", "Added By": "Original Authors"}
{"Name": "The Pile processing scripts", "Description": "A series of scripts to replicate the Pile dataset. Includes filtering and cleaning for: language, profanity, deduplication, and test set decontamination.", "Modalities": ["Text"], "Categories": ["Data Cleaning, Filtering, & Mixing"], "Date": "12-2020", "Primary Link": "GitHub", "Paper Link": "", "Website Link": "", "GitHub Link": "https://github.com/EleutherAI/the-pile/tree/master/processing_scripts", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "BigBench Canaries", "Description": "BigBench's \"Training on the Test Set\" Task provies guidance on using canaries to check if an evaluation set was trained on.", "Modalities": ["Text"], "Categories": ["Data Decontamination"], "Date": "10-2021", "Primary Link": "GitHub", "Paper Link": "", "Website Link": "", "GitHub Link": "https://github.com/google/BIG-bench/blob/main/bigbench/benchmark_tasks/training_on_test_set/README.md#training-on-the-test-set", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Carper AI Decontamination Tool", "Description": "A repository, heavily based by the BigCode repository, to decontaminate evaluation sets from a text training set.", "Modalities": ["Text"], "Categories": ["Data Decontamination"], "Date": "1-2023", "Primary Link": "GitHub", "Paper Link": "", "Website Link": "", "GitHub Link": "https://github.com/CarperAI/decontamination/tree/main", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Data Portraits", "Description": "A tool to test for membership inference of popular datasets, like The Pile or The Stack, i.e. whether a model has seen certain data.", "Modalities": ["Text"], "Categories": ["Data Decontamination"], "Date": "3-2023", "Primary Link": "Webpage", "Paper Link": "https://arxiv.org/abs/2303.03919", "Website Link": "https://dataportraits.org/", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Detect Pretrain Data (Min-K Prob)", "Description": "Detect Pretrain Data (Min-K Prob)", "Modalities": ["Text"], "Categories": ["Data Decontamination"], "Date": "11-2023", "Primary Link": "Webpage", "Paper Link": "https://arxiv.org/abs/2310.16789", "Website Link": "https://swj0419.github.io/detect-pretrain.github.io/", "GitHub Link": "https://github.com/swj0419/detect-pretrain-code", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Interpreting Canary Exposure", "Description": "An explanation on how to interpret canary exposure, including by relating it to membership inference attacks, and differential privacy.", "Modalities": ["Text"], "Categories": ["Data Decontamination"], "Date": "5-2023", "Primary Link": "Paper", "Paper Link": "https://arxiv.org/abs/2306.00133", "Website Link": "", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Proving Test Set Contamination in Black Box Language Models", "Description": "A paper that provides methods for provable guarantees of test set contamination in language models without access to pretraining data or model weights.", "Modalities": ["Text"], "Categories": ["Data Decontamination"], "Date": "10-2023", "Primary Link": "Paper", "Paper Link": "https://arxiv.org/abs/2310.17623", "Website Link": "", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Apricot", "Description": "apricot implements submodular optimization for the purpose of summarizing massive data sets into minimally redundant subsets that are still representative of the original data. These subsets are useful for both visualizing the modalities in the data (such as in the two data sets below) and for training accurate machine learning models with just a fraction of the examples and compute.", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Data Deduplication"], "Date": "7-1905", "Primary Link": "GitHub", "Paper Link": "https://dl.acm.org/doi/abs/10.5555/3455716.3455877", "Website Link": "", "GitHub Link": "https://github.com/jmschrei/apricot", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Datacomp image dedup", "Description": "Data to deduplicate vision datasets for the Datacomp challenge.", "Modalities": ["Vision"], "Categories": ["Data Deduplication"], "Date": "8-2023", "Primary Link": "GitHub", "Paper Link": "", "Website Link": "https://www.datacomp.ai/", "GitHub Link": "https://github.com/mlfoundations/dataset2metadata", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Dolma Dedupe Tool", "Description": "Dolma's text deduplication tool for pretraining data", "Modalities": ["Text"], "Categories": ["Data Deduplication"], "Date": "10-2023", "Primary Link": "GitHub", "Paper Link": "", "Website Link": "", "GitHub Link": "https://github.com/allenai/dolma", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Google Text Deduplication", "Description": "A repository to deduplicate language model datasets. They release the ExactSubstr deduplication implementation (written in Rust) along with scripts to perform ExactSubstr deduplication and inspect the results (written in Python). They also release the document clusters resulting from running NearDup deduplication on C4, RealNews, LM1B, and Wiki-4B-en.", "Modalities": ["Text"], "Categories": ["Data Deduplication"], "Date": "7-2021", "Primary Link": "GitHub", "Paper Link": "https://arxiv.org/abs/2107.06499", "Website Link": "", "GitHub Link": "https://github.com/google-research/deduplicate-text-datasets", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "RedPajama-Data", "Description": "Tools for: exact deduplication with bloom filter, fuzzy deduplication with LSH, calculating quality scores", "Modalities": ["Text"], "Categories": ["Data Deduplication"], "Date": "10-2023", "Primary Link": "GitHub", "Paper Link": "", "Website Link": "", "GitHub Link": "https://github.com/togethercomputer/RedPajama-Data", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Pile", "Description": "A set of tools for deduplication with MinHashLSH", "Modalities": ["Text"], "Categories": ["Data Deduplication"], "Date": "5-2023", "Primary Link": "GitHub", "Paper Link": "https://arxiv.org/abs/2101.00027", "Website Link": "", "GitHub Link": "https://huggingface.co/datasets/EleutherAI/pile-standard-pythia-preshuffled", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Data Cards Playbook", "Description": "A tool to create a Data Card that thoroughly documents a new dataset.", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Data Documentation"], "Date": "6-2022", "Primary Link": "Webpage", "Paper Link": "https://dl.acm.org/doi/fullHtml/10.1145/3531146.3533231", "Website Link": "https://sites.research.google/datacardsplaybook/", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Data Nutrition Labels", "Description": "A generic but thorough form of dataset documentation.", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Data Documentation"], "Date": "2020", "Primary Link": "Webpage", "Paper Link": "https://arxiv.org/abs/1805.03677", "Website Link": "https://datanutrition.org/", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Data Provenance Attribution Card", "Description": "A repository to select datasets and generate a summary. It can also generate a bibtex to attribute all developers of the datasets.", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Data Documentation"], "Date": "10-2023", "Primary Link": "GitHub", "Paper Link": "https://arxiv.org/abs/2310.16787", "Website Link": "https://www.dataprovenance.org/", "GitHub Link": "https://github.com/Data-Provenance-Initiative/Data-Provenance-Collection", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Data Statements", "Description": "A data statement to thoroughly document a new dataset.", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Data Documentation"], "Date": "2018", "Primary Link": "Paper", "Paper Link": "https://aclanthology.org/Q18-1041/", "Website Link": "", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Datasheets for Datasets", "Description": "A datasheet to thoroughly document a new dataset.", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Data Documentation"], "Date": "3-2018", "Primary Link": "Paper", "Paper Link": "https://arxiv.org/abs/1803.09010", "Website Link": "", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Datasheets for Digital Cultural Heritage Datasets", "Description": "A datasheet specifically designed for digital cultural heritage datasets and their considerations.", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Data Documentation"], "Date": "2023", "Primary Link": "Paper", "Paper Link": "https://cris.unibo.it/handle/11585/947893", "Website Link": "", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Data Governance in the Age of Large-Scale Data-Driven Language Technology", "Description": "A paper detailing the data governance decisions undertaken during BigScience's BLOOM project. ", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Data Governance"], "Date": "5-2022", "Primary Link": "Paper", "Paper Link": "https://dl.acm.org/doi/abs/10.1145/3531146.3534637", "Website Link": "", "GitHub Link": "", "HuggingFace Link": "https://huggingface.co/spaces/bigscience-data/roots-search", "Added By": "Original Authors"}
{"Name": "Reclaiming the Digital Commons: A Public Data Trust for Training Data", "Description": "A paper that argues for the creation of a public data trust for collective input into the creation of AI systems and analyzes the feasibility of such a data trust.", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Data Governance"], "Date": "3-2023", "Primary Link": "Paper", "Paper Link": "https://arxiv.org/abs/2303.09001", "Website Link": "", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "BigCode Governance Card", "Description": "A report outlining governance questions, approaches, and tooling in the BigCode project, with a focus on Data governance", "Modalities": ["Text"], "Categories": ["Data Governance"], "Date": "11-2023", "Primary Link": "Paper", "Paper Link": "https://arxiv.org/abs/2312.03872", "Website Link": "", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "AmIinTheStack", "Description": "A tool to let software developers check whether their code was included in TheStack dataset and opt out of inclusion in future versions", "Modalities": ["Text"], "Categories": ["Data Governance"], "Date": "9-2022", "Primary Link": "Hugging Face object", "Paper Link": "", "Website Link": "", "GitHub Link": "", "HuggingFace Link": "https://huggingface.co/spaces/bigcode/in-the-stack", "Added By": "Original Authors"}
{"Name": "StarPII: BigCode Pseudonymization Model", "Description": "A model trained on a new dataset of PII in code used for pseudonymization of a dataset prior to training", "Modalities": ["Text"], "Categories": ["Data Governance"], "Date": "4-2023", "Primary Link": "Hugging Face object", "Paper Link": "", "Website Link": "", "GitHub Link": "", "HuggingFace Link": "https://huggingface.co/bigcode/starpii", "Added By": "Original Authors"}
{"Name": "French DPA Resource sheets on AI and GDPR", "Description": "A set of resource sheets focused on GDPR compliance covering legal basis for data collection, sharing, and best practices for handling personal data", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Data Governance"], "Date": "10-2023", "Primary Link": "Webpage", "Paper Link": "https://www.cnil.fr/en/ai-how-sheets", "Website Link": "", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "AI2 C4 Search Tool", "Description": "A search tool that lets users to execute full-text queries to search Google's C4 Dataset.", "Modalities": ["Text"], "Categories": ["Data Search, Analysis, & Exploration"], "Date": "7-1905", "Primary Link": "Webpage", "Paper Link": "", "Website Link": "https://c4-search.apps.allenai.org/", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Data Finder", "Description": "A tool to help build search over academic datasets given a natural language description of the idea.", "Modalities": ["Text"], "Categories": ["Data Search, Analysis, & Exploration"], "Date": "5-2023", "Primary Link": "GitHub", "Paper Link": "https://arxiv.org/abs/2305.16636", "Website Link": "", "GitHub Link": "https://github.com/viswavi/datafinder", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Data Provenance Explorer", "Description": "An explorer tool for selecting, filtering, and visualizing popular finetuning, instruction, and alignment training datasets from Hugging Face, based on their metadata such as source, license, languages, tasks, topics, among other properties.", "Modalities": ["Text"], "Categories": ["Data Search, Analysis, & Exploration"], "Date": "Frequently Updated", "Primary Link": "Webpage", "Paper Link": "https://arxiv.org/abs/2310.16787", "Website Link": "https://www.dataprovenance.org/", "GitHub Link": "https://github.com/Data-Provenance-Initiative/Data-Provenance-Collection", "HuggingFace Link": "https://huggingface.co/DataProvenanceInitiative", "Added By": "Original Authors"}
{"Name": "GAIA Search Tool", "Description": "A search tool over C4, the Pile, ROOTS, and the text captions of LAION, developed with Pyserini (https://github.com/castorini/pyserini).", "Modalities": ["Text"], "Categories": ["Data Search, Analysis, & Exploration"], "Date": "6-2023", "Primary Link": "Hugging Face object", "Paper Link": "https://arxiv.org/abs/2306.01481", "Website Link": "", "GitHub Link": "", "HuggingFace Link": "https://huggingface.co/spaces/spacerini/gaia", "Added By": "Original Authors"}
{"Name": "Hugging Face Data Measurements Tool", "Description": "A tool to analyze, measure, and compare properties of text finetuning data, including their distributional statistics, lengths, and vocabularies.", "Modalities": ["Text"], "Categories": ["Data Search, Analysis, & Exploration"], "Date": "7-1905", "Primary Link": "Hugging Face object", "Paper Link": "", "Website Link": "", "GitHub Link": "", "HuggingFace Link": "https://huggingface.co/spaces/huggingface/data-measurements-tool", "Added By": "Original Authors"}
{"Name": "Know your data", "Description": "A tool for exploring over 70 vision datasets", "Modalities": ["Vision"], "Categories": ["Data Search, Analysis, & Exploration"], "Date": "5-2021", "Primary Link": "Webpage", "Paper Link": "", "Website Link": "https://knowyourdata-tfds.withgoogle.com/", "GitHub Link": "https://github.com/PAIR-code/knowyourdata", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "LAION search", "Description": "Nearest neighbor search based on CLIP embeddings", "Modalities": ["Text", "Vision"], "Categories": ["Data Search, Analysis, & Exploration"], "Date": "3-2022", "Primary Link": "Webpage", "Paper Link": "", "Website Link": "https://rom1504.github.io/clip-retrieval/", "GitHub Link": "https://github.com/rom1504/clip-retrieval", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "NVIDIA Speech Data Explorer", "Description": "Tool for exploring speech data", "Modalities": ["Speech"], "Categories": ["Data Search, Analysis, & Exploration"], "Date": "Frequently Updated", "Primary Link": "Webpage", "Paper Link": "", "Website Link": "https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/tools/speech_data_explorer.html", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "ROOTS Search Tool", "Description": "A tool, based on a BM25 index, to search over text for each language or group of languages included in the ROOTS pretraining dataset.", "Modalities": ["Text"], "Categories": ["Data Search, Analysis, & Exploration"], "Date": "7-1905", "Primary Link": "Hugging Face object", "Paper Link": "", "Website Link": "", "GitHub Link": "", "HuggingFace Link": "https://huggingface.co/spaces/bigscience-data/roots-search", "Added By": "Original Authors"}
{"Name": "What's In My Big Data?", "Description": "A platform for analyzing large text datasets at scale", "Modalities": ["Text"], "Categories": ["Data Search, Analysis, & Exploration"], "Date": "10-2023", "Primary Link": "Webpage", "Paper Link": "https://arxiv.org/abs/2310.20707", "Website Link": "https://wimbd.apps.allenai.org/", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "WIMBD", "Description": "A dataset analysis tool to count, search, and compare attributes across several massive pretraining corpora at scale, including C4, The Pile, and RedPajama.", "Modalities": ["Text"], "Categories": ["Data Search, Analysis, & Exploration"], "Date": "11-2023", "Primary Link": "Webpage", "Paper Link": "https://arxiv.org/abs/2310.20707", "Website Link": "https://wimbd.apps.allenai.org/", "GitHub Link": "https://github.com/allenai/wimbd", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Everything about Distributed Training and Efficient Finetuning", "Description": "A rundown and crash course in distributed training for deep learning, with an eye toward LLM finetuning and current useful tools and resources. Provides a good overview of the various (distributed) training strategies for efficient and scalable training.", "Modalities": ["Text"], "Categories": ["Model Training: Educational Resources"], "Date": "10-2023", "Primary Link": "Webpage", "Paper Link": "", "Website Link": "https://sumanthrh.com/post/distributed-and-efficient-finetuning/", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Machine Learning Engineering Online Book", "Description": "An \"online textbook\" and resource collection on ML engineering at scale, ranging from debugging distributed systems, parallelism strategies, effective use of large HPC clusters, and chronicles of past large-scale training runs with lessons learned.", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Model Training: Educational Resources"], "Date": "Frequently Updated", "Primary Link": "GitHub", "Paper Link": "", "Website Link": "", "GitHub Link": "https://github.com/stas00/ml-engineering", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "nanoGPT", "Description": "A minimal, stripped-down training codebase for teaching purposes and easily-hackable yet performant small-scale training.", "Modalities": ["Text"], "Categories": ["Model Training: Educational Resources"], "Date": "12-2022", "Primary Link": "GitHub", "Paper Link": "", "Website Link": "", "GitHub Link": "https://github.com/karpathy/nanoGPT", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "The EleutherAI Model Training Cookbook", "Description": "A set of resources on how to train large scale AI systems", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Model Training: Educational Resources"], "Date": "12-2023", "Primary Link": "GitHub", "Paper Link": "", "Website Link": "", "GitHub Link": "https://github.com/EleutherAI/cookbook", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Transformer Inference Arithmetic", "Description": "A blog post on the inference costs of transformer-based LMs. Useful for providing more insight into deep learning accelerators and inference-relevant decisions to make when training a model.", "Modalities": ["Text"], "Categories": ["Model Training: Educational Resources"], "Date": "3-2022", "Primary Link": "Webpage", "Paper Link": "", "Website Link": "https://kipp.ly/transformer-inference-arithmetic/", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Transformer Math 101", "Description": "An introductory blog post on training costs of LLMs, going over useful formulas and considerations from a high to low level", "Modalities": ["Text"], "Categories": ["Model Training: Educational Resources"], "Date": "4-2023", "Primary Link": "Webpage", "Paper Link": "", "Website Link": "https://blog.eleuther.ai/transformer-math/", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Azure Emissions Impact Dashboard", "Description": "Monitoring the environmental impact of training machine learning models on Azure", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Environmental Impact"], "Date": "10-2021", "Primary Link": "Webpage", "Paper Link": "", "Website Link": "https://www.microsoft.com/en-us/sustainability/emissions-impact-dashboard", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Carbontracker", "Description": "carbontracker is a tool for tracking and predicting the energy consumption and carbon footprint of training deep learning models as described in Anthony et al. (2020).", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Environmental Impact"], "Date": "7-2020", "Primary Link": "GitHub", "Paper Link": "https://arxiv.org/abs/2007.03051", "Website Link": "", "GitHub Link": "https://github.com/lfwa/carbontracker", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "CodeCarbon", "Description": "Estimate and track carbon emissions from your computer, quantify and analyze their impact.", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Environmental Impact"], "Date": "11-2020", "Primary Link": "GitHub", "Paper Link": "", "Website Link": "https://mlco2.github.io/codecarbon/", "GitHub Link": "https://github.com/mlco2/codecarbon", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Estimating the Carbon Footprint of BLOOM, a 176B Parameter Language Model", "Description": "A comprehensive account of the broader environmental impact of the BLOOM language model.", "Modalities": ["Text"], "Categories": ["Environmental Impact"], "Date": "6-2023", "Primary Link": "Paper", "Paper Link": "https://jmlr.org/papers/v24/23-0069.html", "Website Link": "", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Experiment Impact Tracker", "Description": "The experiment-impact-tracker is meant to be a simple drop-in method to track energy usage, carbon emissions, and compute utilization of your system. Currently, on Linux systems with Intel chips (that support the RAPL or powergadget interfaces) and NVIDIA GPUs, we record: power draw from CPU and GPU, hardware information, python package versions, estimated carbon emissions information, etc. In California we even support realtime carbon emission information by querying caiso.com!", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Environmental Impact"], "Date": "1-2020", "Primary Link": "GitHub", "Paper Link": "https://arxiv.org/abs/2002.05651", "Website Link": "", "GitHub Link": "https://github.com/Breakend/experiment-impact-tracker", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Google Cloud Carbon Footprint Measurement", "Description": "Tracking the emissions of using Google's cloud compute resources", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Environmental Impact"], "Date": "10-2021", "Primary Link": "Webpage", "Paper Link": "", "Website Link": "https://cloud.google.com/carbon-footprint?hl=en", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Making AI Less \"Thirsty\"", "Description": "Uncovering and Addressing the Secret Water Footprint of AI Models, and estimating water usage for training and deploying LLMs.", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Environmental Impact"], "Date": "4-2023", "Primary Link": "Paper", "Paper Link": "https://arxiv.org/abs/2304.03271", "Website Link": "", "GitHub Link": "https://github.com/Ren-Research/Making-AI-Less-Thirsty", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "ML CO2 Impact", "Description": "A tool for estimating carbon impacts of ML training", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Environmental Impact"], "Date": "10-2019", "Primary Link": "Webpage", "Paper Link": "https://arxiv.org/abs/1910.09700", "Website Link": "https://mlco2.github.io/impact/", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Scaling Laws for Neural Language Models", "Description": "Provide scaling laws to determine the optimal allocation of a fixed compute budget.", "Modalities": ["Text"], "Categories": ["Environmental Impact", "Model Training: Efficiency & Resource Allocation"], "Date": "1-2020", "Primary Link": "Paper", "Paper Link": "https://arxiv.org/abs/2001.08361", "Website Link": "", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Training Compute-Optimal Large Language Models", "Description": "Provides details on the optimal model size and number of tokens for training a transformer-based language model in a given computational budget.", "Modalities": ["Text"], "Categories": ["Environmental Impact"], "Date": "3-2022", "Primary Link": "Paper", "Paper Link": "https://arxiv.org/abs/2203.15556", "Website Link": "", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "AI4Bhārat Indic NLP", "Description": "A repository of Indian language text and speech resources, including datasets.", "Modalities": ["Text", "Speech"], "Categories": ["Finetuning Data Catalogs"], "Date": "Frequently Updated", "Primary Link": "GitHub", "Paper Link": "", "Website Link": "https://ai4bharat.iitm.ac.in/", "GitHub Link": "https://github.com/AI4Bharat", "HuggingFace Link": "https://huggingface.co/ai4bharat", "Added By": "Original Authors"}
{"Name": "Arabic NLP Data Catalogue", "Description": "A catalogue of hundreds of Arabic text and speech finetuning datasets, regularly updated.", "Modalities": ["Text", "Speech"], "Categories": ["Finetuning Data Catalogs"], "Date": "Frequently Updated", "Primary Link": "Webpage", "Paper Link": "", "Website Link": "https://arbml.github.io/masader/", "GitHub Link": "https://github.com/ARBML", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "CHiME-5", "Description": "Speaker Diarization dataset comprising over 50 hours of conversational speech recordings collected from twenty real dinner parties that have taken place in real homes", "Modalities": ["Speech"], "Categories": ["Finetuning Data Catalogs"], "Date": "7-1905", "Primary Link": "Webpage", "Paper Link": "https://licensing.sheffield.ac.uk/product/chime5/print", "Website Link": "https://licensing.sheffield.ac.uk/product/chime5", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Data Provenance Collection", "Description": "A repository and explorer tool for selecting popular finetuning, instruction, and alignment training datasets from Hugging Face, based on data provenance and characteristics criteria.", "Modalities": ["Text"], "Categories": ["Finetuning Data Catalogs"], "Date": "Frequently Updated", "Primary Link": "Webpage", "Paper Link": "https://arxiv.org/abs/2310.16787", "Website Link": "https://www.dataprovenance.org/", "GitHub Link": "https://github.com/Data-Provenance-Initiative/Data-Provenance-Collection", "HuggingFace Link": "https://huggingface.co/DataProvenanceInitiative", "Added By": "Original Authors"}
{"Name": "ImageNet", "Description": "An image classification dataset with 1.3M samples and 1000 classes", "Modalities": ["Vision"], "Categories": ["Finetuning Data Catalogs"], "Date": "6-2009", "Primary Link": "Webpage", "Paper Link": "https://ieeexplore.ieee.org/abstract/document/5206848", "Website Link": "https://www.image-net.org/", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Indonesian NLP Data Catalogue", "Description": "A respository of hundreds of Indonesian language datasets.", "Modalities": ["Text", "Speech"], "Categories": ["Finetuning Data Catalogs"], "Date": "Frequently Updated", "Primary Link": "Webpage", "Paper Link": "", "Website Link": "https://indonlp.github.io/nusa-catalogue/", "GitHub Link": "https://github.com/IndoNLP/nusa-crowd", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Lanfrica", "Description": "An online catalogue that provides links to African language resources (papers and datasets) in both texts and speech", "Modalities": ["Text", "Speech"], "Categories": ["Finetuning Data Catalogs"], "Date": "Frequently Updated", "Primary Link": "Webpage", "Paper Link": "", "Website Link": "https://lanfrica.com/", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Masakhane NLP", "Description": "A repository of African language text and speech resources, including datasets.", "Modalities": ["Text", "Speech"], "Categories": ["Finetuning Data Catalogs"], "Date": "Frequently Updated", "Primary Link": "GitHub", "Paper Link": "", "Website Link": "https://www.masakhane.io/", "GitHub Link": "https://github.com/masakhane-io", "HuggingFace Link": "https://huggingface.co/masakhane", "Added By": "Original Authors"}
{"Name": "MS COCO", "Description": "Object detection, segmentation, captioning and retrieval dataset", "Modalities": ["Text", "Vision"], "Categories": ["Finetuning Data Catalogs"], "Date": "5-2014", "Primary Link": "Webpage", "Paper Link": "https://arxiv.org/abs/1405.0312", "Website Link": "https://cocodataset.org/#home", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "OpenSLR", "Description": "A collection of user-contributed datasets for various speech processing tasks", "Modalities": ["Speech"], "Categories": ["Finetuning Data Catalogs"], "Date": "Frequently Updated", "Primary Link": "Webpage", "Paper Link": "", "Website Link": "https://www.openslr.org/resources.php", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "SEACrowd", "Description": "A repository of hundreds of South East Asian language datasets.", "Modalities": ["Text", "Speech"], "Categories": ["Finetuning Data Catalogs"], "Date": "Frequently Updated", "Primary Link": "Webpage", "Paper Link": "", "Website Link": "https://seacrowd.github.io/seacrowd-catalogue/", "GitHub Link": "https://github.com/SEACrowd", "HuggingFace Link": "https://huggingface.co/NusaCrowd", "Added By": "Original Authors"}
{"Name": "VoxCeleb", "Description": "Speaker Identification dataset comprising of YouTube interviews from thousands of celebrities", "Modalities": ["Speech"], "Categories": ["Finetuning Data Catalogs"], "Date": "6-2017", "Primary Link": "Webpage", "Paper Link": "https://arxiv.org/abs/1706.08612", "Website Link": "https://www.robots.ox.ac.uk/~vgg/data/voxceleb/", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "VoxLingua107", "Description": "Spoken language identification dataset created using audio extracted from YouTube videos retrieved using language-specific search phrases", "Modalities": ["Speech"], "Categories": ["Finetuning Data Catalogs"], "Date": "11-2020", "Primary Link": "Webpage", "Paper Link": "https://arxiv.org/abs/2011.12998", "Website Link": "https://bark.phon.ioc.ee/voxlingua107/", "GitHub Link": "", "HuggingFace Link": "https://huggingface.co/speechbrain/lang-id-voxlingua107-ecapa", "Added By": "Original Authors"}
{"Name": "Zenodo AfricaNLP Community", "Description": "An online catalogue that provides African language resources (data and models) in both texts and speech", "Modalities": ["Text", "Speech"], "Categories": ["Finetuning Data Catalogs"], "Date": "Frequently Updated", "Primary Link": "Webpage", "Paper Link": "", "Website Link": "https://zenodo.org/communities/africanlp", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Axolotl", "Description": "A repository for chat- or instruction-tuning language models, including through full fine-tuning, LoRA, QLoRA, and GPTQ.", "Modalities": ["Text"], "Categories": ["Model Training: Finetuning Repositories"], "Date": "Frequently Updated", "Primary Link": "GitHub", "Paper Link": "", "Website Link": "", "GitHub Link": "https://github.com/OpenAccess-AI-Collective/axolotl", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "BLIP-2", "Description": "Fine-tuned LLMs on multimodal data using a projection layer", "Modalities": ["Text", "Vision"], "Categories": ["Model Training: Finetuning Repositories"], "Date": "1-2023", "Primary Link": "GitHub", "Paper Link": "https://arxiv.org/abs/2301.12597", "Website Link": "", "GitHub Link": "https://github.com/salesforce/LAVIS/tree/main/projects/blip2", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "LLaMA-Adapter", "Description": "Fine-tuned LLMs on multimodal data using adapters", "Modalities": ["Text", "Vision"], "Categories": ["Model Training: Finetuning Repositories"], "Date": "3-2023", "Primary Link": "GitHub", "Paper Link": "https://arxiv.org/abs/2304.15010", "Website Link": "", "GitHub Link": "https://github.com/OpenGVLab/LLaMA-Adapter", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "LLaMA-Factory", "Description": "A framework for efficiently fine-tuning LLMs using cutting-edge algorithms with a user-friendly web UI", "Modalities": ["Text"], "Categories": ["Model Training: Finetuning Repositories"], "Date": "Frequently Updated", "Primary Link": "GitHub", "Paper Link": "https://arxiv.org/abs/2403.13372", "Website Link": "", "GitHub Link": "https://github.com/hiyouga/LLaMA-Factory", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "LLaVA", "Description": "Fine-tuned LLMs on multimodal data using a projection layer", "Modalities": ["Text", "Vision"], "Categories": ["Model Training: Finetuning Repositories"], "Date": "4-2023", "Primary Link": "Webpage", "Paper Link": "https://arxiv.org/abs/2310.03744", "Website Link": "https://llava-vl.github.io/", "GitHub Link": "https://github.com/haotian-liu/LLaVA", "HuggingFace Link": "https://huggingface.co/spaces/badayvedat/LLaVA", "Added By": "Original Authors"}
{"Name": "MiniGPT4", "Description": "Fine-tuned LLMs on multimodal data using a projection layer", "Modalities": ["Text", "Vision"], "Categories": ["Model Training: Finetuning Repositories"], "Date": "4-2023", "Primary Link": "Webpage", "Paper Link": "https://arxiv.org/abs/2304.10592", "Website Link": "https://minigpt-4.github.io/", "GitHub Link": "https://github.com/Vision-CAIR/MiniGPT-4", "HuggingFace Link": "https://huggingface.co/spaces/Vision-CAIR/minigpt4", "Added By": "Original Authors"}
{"Name": "OpenFlamingo", "Description": "Open source implementation of Flamingo", "Modalities": ["Text", "Vision"], "Categories": ["Model Training: Finetuning Repositories"], "Date": "3-2023", "Primary Link": "GitHub", "Paper Link": "https://arxiv.org/abs/2308.01390", "Website Link": "https://laion.ai/blog/open-flamingo-v2/", "GitHub Link": "https://github.com/mlfoundations/open_flamingo", "HuggingFace Link": "https://huggingface.co/openflamingo", "Added By": "Original Authors"}
{"Name": "Otter", "Description": "Multimodal models with Flamingo architecture", "Modalities": ["Text", "Vision"], "Categories": ["Model Training: Finetuning Repositories"], "Date": "4-2023", "Primary Link": "GitHub", "Paper Link": "https://arxiv.org/abs/2311.04219", "Website Link": "", "GitHub Link": "https://github.com/Luodian/Otter", "HuggingFace Link": "https://huggingface.co/spaces/Otter-AI/OtterHD-Demo", "Added By": "Original Authors"}
{"Name": "peft", "Description": "A library for doing parameter efficient finetuning", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Model Training: Finetuning Repositories"], "Date": "Frequently Updated", "Primary Link": "GitHub", "Paper Link": "", "Website Link": "", "GitHub Link": "https://github.com/huggingface/peft", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "trl", "Description": "A library for doing RLHF on LLMs.", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Model Training: Finetuning Repositories"], "Date": "Frequently Updated", "Primary Link": "GitHub", "Paper Link": "", "Website Link": "", "GitHub Link": "https://github.com/huggingface/trl", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "trlX", "Description": "A library for doing RLHF on LLMs.", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Model Training: Finetuning Repositories"], "Date": "Frequently Updated", "Primary Link": "GitHub", "Paper Link": "https://aclanthology.org/2023.emnlp-main.530/", "Website Link": "https://trlx.readthedocs.io/en/latest/", "GitHub Link": "https://github.com/CarperAI/trlx", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Levanter", "Description": "Levanter is a framework for training large language models (LLMs) and other foundation models that strives for legibility, scalability, and reproducibility:", "Modalities": ["Text"], "Categories": ["Model Training: Finetuning Repositories", "Model Training: Pretraining Repositories"], "Date": "6-2023", "Primary Link": "GitHub", "Paper Link": "", "Website Link": "https://crfm.stanford.edu/2023/06/16/levanter-1_0-release.html", "GitHub Link": "https://github.com/stanford-crfm/levanter", "HuggingFace Link": "https://huggingface.co/stanford-crfm", "Added By": "Original Authors"}
{"Name": "AI Licensing Can’t Balance “Open” with “Responsible”", "Description": "A blog post by an IP lawyer arguing against responsible use licensing", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["License Selection"], "Date": "7-2023", "Primary Link": "Webpage", "Paper Link": "", "Website Link": "https://katedowninglaw.com/2023/07/13/ai-licensing-cant-balance-open-with-responsible/", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "AI Pubs Open RAIL-M License", "Description": "Template for a responsible AI model license where the model is intended for research use. Use restrictions relate to discrimination, transparency, and violating the law", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["License Selection"], "Date": "3-2023", "Primary Link": "Webpage", "Paper Link": "", "Website Link": "https://www.licenses.ai/ai-pubs-open-railm-vz1", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "AI2 ImpACT-LR License", "Description": "License for low risk AI artifacts (data and models) that allows for distribution of the artifact and its derivatives. Use restrictions include weapons development and military surveillance", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["License Selection"], "Date": "7-2023", "Primary Link": "Webpage", "Paper Link": "", "Website Link": "https://allenai.org/licenses/impact-lr", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "AI2 ImpACT-MR License", "Description": "License for medium risk AI artifacts (data and models) that does not allows for distribution of the artifact but does allow for distribution of its derivatives. Use restrictions include weapons development and military surveillance", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["License Selection"], "Date": "7-2023", "Primary Link": "Webpage", "Paper Link": "", "Website Link": "https://allenai.org/licenses/impact-mr", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Apache 2.0 License", "Description": "The most common open-source license for model weights", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["License Selection"], "Date": "1-2004", "Primary Link": "Webpage", "Paper Link": "", "Website Link": "https://www.apache.org/licenses/LICENSE-2.0", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Behavioral Use Licensing for Responsible AI", "Description": "A paper that provides a theoretical framework for licenses inteded for open models with use restrictions", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["License Selection"], "Date": "6-2022", "Primary Link": "Paper", "Paper Link": "https://dl.acm.org/doi/10.1145/3531146.3533143", "Website Link": "", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "BigCode Open RAIL-M License", "Description": "Template for a responsible AI model license. Use restrictions include generation and dissemination of malware", "Modalities": ["Text"], "Categories": ["License Selection"], "Date": "5-2023", "Primary Link": "Hugging Face object", "Paper Link": "", "Website Link": "", "GitHub Link": "", "HuggingFace Link": "https://huggingface.co/spaces/bigcode/bigcode-model-license-agreement", "Added By": "Original Authors"}
{"Name": "BigScience Open RAIL-M License", "Description": "Template for a responsible AI model license. Use restrictions include defamation, disinformation, and discrimination", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["License Selection"], "Date": "8-2022", "Primary Link": "Webpage", "Paper Link": "", "Website Link": "https://static1.squarespace.com/static/5c2a6d5c45776e85d1482a7e/t/6308bb4bba3a2a045b72a4b0/1661516619868/BigScience+Open+RAIL-M+License.pdf", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Choose an open source license", "Description": "A guide for choosing among open source licenses that includes general selection criteria and explanations for software licenses", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["License Selection"], "Date": "Frequently Updated", "Primary Link": "GitHub", "Paper Link": "", "Website Link": "https://choosealicense.com/", "GitHub Link": "https://github.com/github/choosealicense.com/tree/gh-pages", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Create Commons License Chooser", "Description": "A guide for choosing among Creative Commons licenses with an explanation of how they function", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["License Selection"], "Date": "Frequently Updated", "Primary Link": "Webpage", "Paper Link": "", "Website Link": "https://chooser-beta.creativecommons.org/", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Legal Playbook For Natural Language Processing Researchers", "Description": "This playbook is a legal research resource for various activities related to data gathering, data governance, and disposition of an AI model available as a public resource.", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["License Selection"], "Date": "7-1905", "Primary Link": "Webpage", "Paper Link": "", "Website Link": "https://bigscience.huggingface.co/blog/legal-playbook-for-natural-language-processing-researchers", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Licensing is neither feasible nor effective for addressing AI risks", "Description": "Argues that licensing is not the correct way to address risks with AI systems", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["License Selection"], "Date": "6-2023", "Primary Link": "Webpage", "Paper Link": "", "Website Link": "https://www.aisnakeoil.com/p/licensing-is-neither-feasible-nor", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Open RAIL-S License", "Description": "Template for a responsible AI source code license. Use restrictions relate to surveillance, synthetic media, healthcare and the criminal legal system", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["License Selection"], "Date": "11-2023", "Primary Link": "Webpage", "Paper Link": "", "Website Link": "https://www.licenses.ai/source-code-license", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Primer on AI2 ImpACT Licenses", "Description": "A post by AI2 describing when and why an organization should use a specific ImpACT license", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["License Selection"], "Date": "7-2023", "Primary Link": "Webpage", "Paper Link": "", "Website Link": "https://allenai.org/impact-license", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "The Open Source Definition", "Description": "The definition of an \"open source\" license", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["License Selection"], "Date": "2-2023", "Primary Link": "Webpage", "Paper Link": "", "Website Link": "https://opensource.org/osd/", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "The Turning Way, Licensing", "Description": "A guide to reproducible research and licensing", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["License Selection"], "Date": "Frequently Updated", "Primary Link": "Webpage", "Paper Link": "", "Website Link": "https://the-turing-way.netlify.app/reproducible-research/licensing", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "What is Free Software?", "Description": "A philosophical argument for why free software licenses are important", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["License Selection"], "Date": "2-2023", "Primary Link": "Webpage", "Paper Link": "", "Website Link": "https://www.gnu.org/philosophy/free-sw.en.html", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Ecosystem Cards", "Description": "Ecosystem Graphs centralize information about models and their impact in the broader ecosystem. ", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Model Documentation"], "Date": "3-2023", "Primary Link": "Webpage", "Paper Link": "https://arxiv.org/abs/2303.15772", "Website Link": "https://hai.stanford.edu/news/ecosystem-graphs-social-footprint-foundation-models", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Foundation Model Transparency Index", "Description": "An index to measure the transparency of a foundation model with respect to its inputs, development, and downstream uses or policies.", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Model Documentation"], "Date": "10-2023", "Primary Link": "Webpage", "Paper Link": "https://arxiv.org/abs/2310.12941", "Website Link": "https://crfm.stanford.edu/fmti/", "GitHub Link": "https://github.com/stanford-crfm/fmti", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Model Card Resources", "Description": "A release of several resources surrounding model cards, including templates and tools for easy documentation creation, and how these are frequently used in practice.", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Model Documentation"], "Date": "12-2022", "Primary Link": "Webpage", "Paper Link": "", "Website Link": "https://huggingface.co/blog/model-cards", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Model Cards", "Description": "A standard for reporting and documenting machine learning models, for promoting and easing transparent and open model development or reporting.", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Model Documentation"], "Date": "10-2018", "Primary Link": "Paper", "Paper Link": "https://arxiv.org/abs/1810.03993", "Website Link": "https://huggingface.co/spaces/huggingface/Model_Cards_Writing_Tool", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Hugging Face ML Research Release Toolkit ", "Description": "A new researcher guide to releasing model or data resources, documenting the research and Hugging Face objects.", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Model Documentation"], "Date": "12-2023", "Primary Link": "Webpage", "Paper Link": "", "Website Link": "https://docs.google.com/document/d/1EOxyZ11piIIRLDlhofX8nfnU0mHCU-TZ3EU4tx5g9aE/edit#heading=h.8zrjwmlee7ge", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "C4", "Description": "An English, cleaned version of Common Crawl's web crawl corpus (https://commoncrawl.org).", "Modalities": ["Text"], "Categories": ["Pretraining Data Sources"], "Date": "4-2019", "Primary Link": "Hugging Face object", "Paper Link": "https://arxiv.org/abs/1910.10683", "Website Link": "https://commoncrawl.org", "GitHub Link": "https://github.com/google-research/text-to-text-transfer-transformer#c4", "HuggingFace Link": "https://huggingface.co/datasets/allenai/c4", "Added By": "Original Authors"}
{"Name": "Common Voice", "Description": "28k hours [as of 11/2023] of crowd-sourced read speech from 100+ languages", "Modalities": ["Speech"], "Categories": ["Pretraining Data Sources"], "Date": "11-2023", "Primary Link": "Webpage", "Paper Link": "", "Website Link": "https://commonvoice.mozilla.org/en/datasets", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "CulturaX", "Description": "A pertaining dataset of 16T tokens, covering 167 languages, cleaned, deduplicated, and refined. Combines mC4 into 2020, with OSCAR project data up to 2023.", "Modalities": ["Text"], "Categories": ["Pretraining Data Sources"], "Date": "9-2023", "Primary Link": "Hugging Face object", "Paper Link": "https://arxiv.org/abs/2309.09400", "Website Link": "", "GitHub Link": "", "HuggingFace Link": "https://huggingface.co/datasets/uonlp/CulturaX", "Added By": "Original Authors"}
{"Name": "DataComp-1B and CommonPool-13B", "Description": "A large pool of 13B image-text pairs from CommonCrawl and a curated 1B subset", "Modalities": ["Text", "Vision"], "Categories": ["Pretraining Data Sources"], "Date": "4-2023", "Primary Link": "Webpage", "Paper Link": "https://arxiv.org/abs/2304.14108", "Website Link": "https://www.datacomp.ai/", "GitHub Link": "https://github.com/mlfoundations/datacomp", "HuggingFace Link": "https://huggingface.co/datasets/mlfoundations/datacomp_1b", "Added By": "Original Authors"}
{"Name": "Dolma", "Description": "A pretraining dataset of 3 trillion tokens from a diverse mix of web content, academic publications, code, books, and encyclopedic materials.", "Modalities": ["Text"], "Categories": ["Pretraining Data Sources"], "Date": "8-2023", "Primary Link": "Hugging Face object", "Paper Link": "https://arxiv.org/abs/2402.00159", "Website Link": "", "GitHub Link": "https://github.com/allenai/dolma", "HuggingFace Link": "https://huggingface.co/datasets/allenai/dolma", "Added By": "Original Authors"}
{"Name": "GigaSpeech", "Description": "40k hours (10k transcribed) multi-domain English speech corpus", "Modalities": ["Speech"], "Categories": ["Pretraining Data Sources"], "Date": "7-1905", "Primary Link": "GitHub", "Paper Link": "https://arxiv.org/abs/2106.06909", "Website Link": "", "GitHub Link": "https://github.com/SpeechColab/GigaSpeech", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Golos", "Description": "1,240 hours of crowd-sourced Russian speech", "Modalities": ["Speech"], "Categories": ["Pretraining Data Sources"], "Date": "6-2021", "Primary Link": "Webpage", "Paper Link": "https://arxiv.org/abs/2106.10161", "Website Link": "https://www.openslr.org/114/", "GitHub Link": "https://github.com/sberdevices/golos", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "IndicCorp v2", "Description": "A multilingual pre-training corpus  for 24 Indian languages", "Modalities": ["Text"], "Categories": ["Pretraining Data Sources"], "Date": "5-2023", "Primary Link": "GitHub", "Paper Link": "https://aclanthology.org/2023.acl-long.693/", "Website Link": "", "GitHub Link": "https://github.com/AI4Bharat/IndicBERT/tree/main#indiccorp-v2", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "IndicSUPERB", "Description": "1,684 hour crowd-sourced corpus of 12 Indian languages", "Modalities": ["Speech"], "Categories": ["Pretraining Data Sources"], "Date": "8-2022", "Primary Link": "Webpage", "Paper Link": "https://arxiv.org/abs/2208.11761", "Website Link": "https://ai4bharat.iitm.ac.in/indicsuperb/", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Libri-Light", "Description": "60k hour read English speech from LibriVox audiobooks", "Modalities": ["Speech"], "Categories": ["Pretraining Data Sources"], "Date": "12-2019", "Primary Link": "GitHub", "Paper Link": "https://arxiv.org/abs/1912.07875", "Website Link": "", "GitHub Link": "https://github.com/facebookresearch/libri-light", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "LibriSpeech", "Description": "960 hour read English speech from LibriVox audiobooks", "Modalities": ["Speech"], "Categories": ["Pretraining Data Sources"], "Date": "7-1905", "Primary Link": "Webpage", "Paper Link": "http://www.danielpovey.com/files/2015_icassp_librispeech.pdf", "Website Link": "https://www.openslr.org/12/", "GitHub Link": "", "HuggingFace Link": "https://huggingface.co/datasets/librispeech_asr", "Added By": "Original Authors"}
{"Name": "MADLAD-400", "Description": "A manually audited, general domain 3T token monolingual dataset based on CommonCrawl, spanning 419 languages.", "Modalities": ["Text"], "Categories": ["Pretraining Data Sources"], "Date": "9-2023", "Primary Link": "Hugging Face object", "Paper Link": "https://arxiv.org/abs/2309.04662", "Website Link": "", "GitHub Link": "https://github.com/google-research/google-research/tree/master/madlad_400", "HuggingFace Link": "https://huggingface.co/datasets/allenai/MADLAD-400", "Added By": "Original Authors"}
{"Name": "mC4", "Description": "The fully multilingual, cleaned version of Common Crawl's web crawl corpus (https://commoncrawl.org).", "Modalities": ["Text"], "Categories": ["Pretraining Data Sources"], "Date": "4-2019", "Primary Link": "Hugging Face object", "Paper Link": "https://arxiv.org/abs/1910.10683", "Website Link": "https://commoncrawl.org", "GitHub Link": "", "HuggingFace Link": "https://huggingface.co/datasets/mc4", "Added By": "Original Authors"}
{"Name": "MMC4", "Description": "Interleaved image-text data from Common Crawl (570M images, 43B tokens)", "Modalities": ["Text", "Vision"], "Categories": ["Pretraining Data Sources"], "Date": "4-2023", "Primary Link": "GitHub", "Paper Link": "https://arxiv.org/abs/2304.06939", "Website Link": "", "GitHub Link": "https://github.com/allenai/mmc4", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "OBELICS", "Description": "Interleaved image-text data from Common Crawl (353 M images, 115B tokens)", "Modalities": ["Text", "Vision"], "Categories": ["Pretraining Data Sources"], "Date": "6-2023", "Primary Link": "GitHub", "Paper Link": "https://arxiv.org/abs/2306.16527", "Website Link": "https://huggingface.co/blog/idefics", "GitHub Link": "https://github.com/huggingface/OBELICS", "HuggingFace Link": "https://huggingface.co/datasets/HuggingFaceM4/OBELICS", "Added By": "Original Authors"}
{"Name": "OLC", "Description": "The Open License Corpus is a 228B token corpus of permissively-licensed, primarily English text data for pretraining.", "Modalities": ["Text"], "Categories": ["Pretraining Data Sources"], "Date": "8-2023", "Primary Link": "GitHub", "Paper Link": "https://arxiv.org/abs/2308.04430", "Website Link": "", "GitHub Link": "https://github.com/kernelmachine/silo-lm#download-data", "HuggingFace Link": "https://huggingface.co/datasets/kernelmachine/open-license-corpus", "Added By": "Original Authors"}
{"Name": "OpenWebMath", "Description": "A dataset containing the majority of the high-quality, mathematical text from the internet. It is filtered and extracted from over 200B HTML files on Common Crawl down to a set of 6.3 million documents containing a total of 14.7B tokens.", "Modalities": ["Text"], "Categories": ["Pretraining Data Sources"], "Date": "10-2023", "Primary Link": "Hugging Face object", "Paper Link": "https://arxiv.org/abs/2310.06786", "Website Link": "", "GitHub Link": "https://github.com/keirp/OpenWebMath", "HuggingFace Link": "https://huggingface.co/datasets/open-web-math/open-web-math", "Added By": "Original Authors"}
{"Name": "OPUS", "Description": "The Open Parallel Corpus is a massive collection of translated text pairs from the web.", "Modalities": ["Text"], "Categories": ["Pretraining Data Sources"], "Date": "Frequently Updated", "Primary Link": "Webpage", "Paper Link": "", "Website Link": "https://opus.nlpl.eu/", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "OSCAR", "Description": "The Open Super-large Crawled Aggregated coRpus provides web-based multilingual datasets across 166 languages.", "Modalities": ["Text"], "Categories": ["Pretraining Data Sources"], "Date": "Frequently Updated", "Primary Link": "Webpage", "Paper Link": "https://aclanthology.org/2022.wnut-1.23/", "Website Link": "https://oscar-project.org/", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "peS2o", "Description": "A collection of ~40M creative open-access academic papers, cleaned, filtered, and formatted for pre-training of language models, originally derived from the Semantic Scholar Open Research Corpus (S2ORC).", "Modalities": ["Text"], "Categories": ["Pretraining Data Sources"], "Date": "1-2023", "Primary Link": "Hugging Face object", "Paper Link": "https://arxiv.org/abs/1911.02782", "Website Link": "", "GitHub Link": "", "HuggingFace Link": "https://huggingface.co/datasets/allenai/peS2o", "Added By": "Original Authors"}
{"Name": "Pile of Law", "Description": "An open-source, English dataset with ∼256GB of legal and administrative data, covering court opinions, contracts, administrative rules, and legislative records.", "Modalities": ["Text"], "Categories": ["Pretraining Data Sources"], "Date": "11-2022", "Primary Link": "Hugging Face object", "Paper Link": "https://arxiv.org/abs/2207.00220", "Website Link": "", "GitHub Link": "", "HuggingFace Link": "https://huggingface.co/datasets/pile-of-law/pile-of-law", "Added By": "Original Authors"}
{"Name": "RedPajama v2", "Description": "A pretraining dataset of 30 trillion filtered and deduplicated tokens (100+ trillions raw) from 84 CommonCrawl dumps covering 5 languages, along with 40+ pre-computed data quality annotations that can be used for further filtering and weighting.", "Modalities": ["Text"], "Categories": ["Pretraining Data Sources"], "Date": "10-2023", "Primary Link": "Hugging Face object", "Paper Link": "", "Website Link": "https://www.together.ai/blog/redpajama-data-v2", "GitHub Link": "https://github.com/togethercomputer/RedPajama-Data", "HuggingFace Link": "https://huggingface.co/datasets/togethercomputer/RedPajama-Data-V2", "Added By": "Original Authors"}
{"Name": "ROOTS", "Description": "A massive multilingual pretraining corpus from BigScience, comprised of 1.6TB of text spanning 59 languages. It is a mix of OSCAR (https://oscar-project.org/) and the datasets found in the BigScience Catalogue (https://huggingface.co/spaces/bigscience/SourcingCatalog).", "Modalities": ["Text"], "Categories": ["Pretraining Data Sources"], "Date": "5-2022", "Primary Link": "Hugging Face object", "Paper Link": "https://arxiv.org/abs/2303.03915", "Website Link": "https://bigscience.huggingface.co/", "GitHub Link": "https://github.com/bigscience-workshop/bigscience/tree/master/data", "HuggingFace Link": "https://huggingface.co/bigscience-data", "Added By": "Original Authors"}
{"Name": "Samrómur", "Description": "2,200 hour crowd-sourced corpus of Icelandic speech", "Modalities": ["Speech"], "Categories": ["Pretraining Data Sources"], "Date": "7-1905", "Primary Link": "Webpage", "Paper Link": "", "Website Link": "https://www.openslr.org/128/", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Shrutilipi", "Description": "6,400 hour corpus of TV/Radio broadcasts from 12 Indian languages", "Modalities": ["Speech"], "Categories": ["Pretraining Data Sources"], "Date": "8-2022", "Primary Link": "Webpage", "Paper Link": "https://arxiv.org/abs/2208.12666", "Website Link": "https://ai4bharat.iitm.ac.in/shrutilipi/", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "The People’s Speech", "Description": "30k hour conversational English dataset", "Modalities": ["Speech"], "Categories": ["Pretraining Data Sources"], "Date": "11-2021", "Primary Link": "Hugging Face object", "Paper Link": "https://arxiv.org/abs/2111.09344", "Website Link": "", "GitHub Link": "", "HuggingFace Link": "https://huggingface.co/datasets/MLCommons/peoples_speech", "Added By": "Original Authors"}
{"Name": "The Pile", "Description": "An 825GB English pretraining corpus that mixes portions of common crawl with 22 smaller, high-quality datasets combined together.", "Modalities": ["Text"], "Categories": ["Pretraining Data Sources"], "Date": "12-2020", "Primary Link": "Webpage", "Paper Link": "https://arxiv.org/abs/2101.00027", "Website Link": "https://pile.eleuther.ai/", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "The Proof Pile 2", "Description": "The Proof-Pile-2 is a 55 billion token dataset of mathematical and scientific documents.", "Modalities": ["Text"], "Categories": ["Pretraining Data Sources"], "Date": "9-2023", "Primary Link": "Hugging Face object", "Paper Link": "https://arxiv.org/abs/2310.10631", "Website Link": "https://blog.eleuther.ai/llemma/", "GitHub Link": "https://github.com/EleutherAI/math-lm", "HuggingFace Link": "https://huggingface.co/datasets/EleutherAI/proof-pile-2", "Added By": "Original Authors"}
{"Name": "The RefinedWeb", "Description": "An English-only,  web-only, deduplicated pretraining dataset of five trillion tokens.", "Modalities": ["Text"], "Categories": ["Pretraining Data Sources"], "Date": "6-2023", "Primary Link": "Hugging Face object", "Paper Link": "https://arxiv.org/abs/2306.01116", "Website Link": "", "GitHub Link": "", "HuggingFace Link": "https://huggingface.co/datasets/tiiuae/falcon-refinedweb", "Added By": "Original Authors"}
{"Name": "The Stack", "Description": "The Stack is a 6TB, permissively-licensed pretraining dataset from active GitHub repositories covering 358 programming languages.", "Modalities": ["Text"], "Categories": ["Pretraining Data Sources"], "Date": "11-2022", "Primary Link": "Hugging Face object", "Paper Link": "https://arxiv.org/abs/2211.15533", "Website Link": "https://www.bigcode-project.org/docs/about/the-stack/#datasets-and-data-governance-tools-released-by-bigcode", "GitHub Link": "https://github.com/bigcode-project/bigcode-dataset", "HuggingFace Link": "https://huggingface.co/datasets/bigcode/the-stack", "Added By": "Original Authors"}
{"Name": "VoxPopuli", "Description": "400k hours of unlabelled speech from 23 languages of the European parliament", "Modalities": ["Speech"], "Categories": ["Pretraining Data Sources"], "Date": "1-2021", "Primary Link": "GitHub", "Paper Link": "https://arxiv.org/abs/2101.00390", "Website Link": "", "GitHub Link": "https://github.com/facebookresearch/voxpopuli", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "WebVid-10M", "Description": "10M videos with captions", "Modalities": ["Text", "Vision"], "Categories": ["Pretraining Data Sources"], "Date": "4-2021", "Primary Link": "Webpage", "Paper Link": "https://arxiv.org/abs/2104.00650", "Website Link": "https://maxbain.com/webvid-dataset/", "GitHub Link": "https://github.com/m-bain/webvid", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "WenetSpeech", "Description": "22.4k hour multi-domain corpus of Mandarin", "Modalities": ["Speech"], "Categories": ["Pretraining Data Sources"], "Date": "10-2021", "Primary Link": "Webpage", "Paper Link": "https://arxiv.org/abs/2110.03370", "Website Link": "https://www.openslr.org/121/", "GitHub Link": "https://github.com/wenet-e2e/WenetSpeech", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "WURA", "Description": "A manually audited multilingual pre-training corpus (document-level dataset) for 16 African languages and four  high-resource languages widely spoken in Africa (English, French, Arabic and Portuguese)", "Modalities": ["Text"], "Categories": ["Pretraining Data Sources"], "Date": "11-2023", "Primary Link": "Hugging Face object", "Paper Link": "https://aclanthology.org/2023.emnlp-main.11/", "Website Link": "", "GitHub Link": "", "HuggingFace Link": "https://huggingface.co/datasets/castorini/wura", "Added By": "Original Authors"}
{"Name": "WebDatasets", "Description": "A dataset format for high-performance streaming of data. Especially useful for modalities other than language that are more I/O intensive for training', such as images, video, or audio.", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Pretraining Data Sources"], "Date": "Frequently Updated", "Primary Link": "GitHub", "Paper Link": "", "Website Link": "", "GitHub Link": "https://github.com/webdataset/webdataset", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Multi Legal Pile", "Description": "A large-scale multilingual legal dataset and superset of the Pile of Law, suited for pretraining language models. It spans over 24 languages and five legal text types.", "Modalities": ["Text"], "Categories": ["Pretraining Data Sources"], "Date": "6-2023", "Primary Link": "Hugging Face object", "Paper Link": "https://arxiv.org/abs/2306.02069", "Website Link": "", "GitHub Link": "", "HuggingFace Link": "https://huggingface.co/datasets/joelniklaus/Multi_Legal_Pile", "Added By": "Original Authors"}
{"Name": "GPT-NeoX", "Description": "A library for training large language models, built off Megatron-DeepSpeed and Megatron-LM with an easier user interface. Used at massive scale on a variety of clusters and hardware setups.", "Modalities": ["Text"], "Categories": ["Model Training: Pretraining Repositories"], "Date": "Frequently Updated", "Primary Link": "GitHub", "Paper Link": "", "Website Link": "", "GitHub Link": "https://github.com/EleutherAI/gpt-neox", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Kosmos-2", "Description": "For training multimodal models with CLIP backbones.", "Modalities": ["Text", "Vision"], "Categories": ["Model Training: Pretraining Repositories"], "Date": "6-2023", "Primary Link": "GitHub", "Paper Link": "https://arxiv.org/abs/2306.14824", "Website Link": "", "GitHub Link": "https://github.com/microsoft/unilm/tree/master/kosmos-2", "HuggingFace Link": "https://huggingface.co/spaces/ydshieh/Kosmos-2", "Added By": "Original Authors"}
{"Name": "Lhotse", "Description": "Python library for handling speech data in machine learning projects", "Modalities": ["Speech"], "Categories": ["Model Training: Pretraining Repositories"], "Date": "10-2023", "Primary Link": "GitHub", "Paper Link": "", "Website Link": "https://github.com/lhotse-speech/lhotse", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Megatron-DeepSpeed", "Description": "A library for training large language models, built off of Megatron-LM but extended by Microsoft to support features of their DeepSpeed library.", "Modalities": ["Text"], "Categories": ["Model Training: Pretraining Repositories"], "Date": "Frequently Updated", "Primary Link": "GitHub", "Paper Link": "", "Website Link": "", "GitHub Link": "https://github.com/microsoft/Megatron-DeepSpeed", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Megatron-LM", "Description": "One of the earliest open-source pretraining codebases for large language models. Still updated and has been used for a number of landmark distributed training and parallelism research papers by NVIDIA.", "Modalities": ["Text"], "Categories": ["Model Training: Pretraining Repositories"], "Date": "", "Primary Link": "GitHub", "Paper Link": "", "Website Link": "", "GitHub Link": "https://github.com/NVIDIA/Megatron-LM", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "OpenCLIP", "Description": "Supports training and inference for over 100 CLIP models", "Modalities": ["Text", "Vision"], "Categories": ["Model Training: Pretraining Repositories"], "Date": "9-2021", "Primary Link": "GitHub", "Paper Link": "", "Website Link": "", "GitHub Link": "https://github.com/mlfoundations/open_clip", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "OpenLM", "Description": "OpenLM is a minimal language modeling repository, aimed to facilitate research on medium sized LMs. They have verified the performance of OpenLM up to 7B parameters and 256 GPUs. They only depend only on PyTorch, XFormers, or Triton.", "Modalities": ["Text"], "Categories": ["Model Training: Pretraining Repositories"], "Date": "Frequently Updated", "Primary Link": "GitHub", "Paper Link": "", "Website Link": "", "GitHub Link": "https://github.com/mlfoundations/open_lm", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Pytorch Image Models (timm)", "Description": "Hub for models, scripts and pre-trained weights for image classification models.", "Modalities": ["Vision"], "Categories": ["Model Training: Pretraining Repositories"], "Date": "5-2019", "Primary Link": "GitHub", "Paper Link": "", "Website Link": "", "GitHub Link": "https://github.com/huggingface/pytorch-image-models", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Stable Audio Tools", "Description": "A codebase for distributed training of generative audio models.", "Modalities": ["Speech"], "Categories": ["Model Training: Pretraining Repositories"], "Date": "Frequently Updated", "Primary Link": "GitHub", "Paper Link": "", "Website Link": "", "GitHub Link": "https://github.com/Stability-AI/stable-audio-tools", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Bias Benchmark for QA (BBQ)", "Description": "A dataset of question-sets constructed by the authors that highlight attested social biases against people belonging to protected classes along nine different social dimensions relevant for U.S. English-speaking contexts.", "Modalities": ["Text"], "Categories": ["Model Evaluation: Risks & Harms"], "Date": "10-2021", "Primary Link": "GitHub", "Paper Link": "https://arxiv.org/abs/2110.08193", "Website Link": "", "GitHub Link": "https://github.com/nyu-mll/BBQ", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Crossmodal-3600", "Description": "Image captioning evaluation with geographically diverse images in 36 languages", "Modalities": ["Text", "Vision"], "Categories": ["Model Evaluation: Risks & Harms"], "Date": "5-2022", "Primary Link": "GitHub", "Paper Link": "https://arxiv.org/abs/2205.12522", "Website Link": "", "GitHub Link": "https://google.github.io/crossmodal-3600/", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "FactualityPrompt", "Description": "A benchmark to measure factuality in language models.", "Modalities": ["Text"], "Categories": ["Model Evaluation: Risks & Harms"], "Date": "6-2022", "Primary Link": "GitHub", "Paper Link": "https://arxiv.org/abs/2206.04624", "Website Link": "", "GitHub Link": "https://github.com/nayeon7lee/FactualityPrompt", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "From text to talk", "Description": "Harnessing conversational corpora for humane and diversity-aware language technology. They show how interactional data from 63 languages (26 families) harbours insights about turn-taking, timing, sequential structure and social action.", "Modalities": ["Speech"], "Categories": ["Model Evaluation: Risks & Harms"], "Date": "5-2022", "Primary Link": "Paper", "Paper Link": "https://aclanthology.org/2022.acl-long.385/ ", "Website Link": "", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Hallucinations", "Description": "Public LLM leaderboard computed using Vectara's Hallucination Evaluation Model. This evaluates how often an LLM introduces hallucinations when summarizing a document. ", "Modalities": ["Text"], "Categories": ["Model Evaluation: Risks & Harms"], "Date": "10-2023", "Primary Link": "GitHub", "Paper Link": "", "Website Link": "https://github.com/vectara/hallucination-leaderboard", "GitHub Link": "", "HuggingFace Link": "https://huggingface.co/vectara/hallucination_evaluation_model", "Added By": "Original Authors"}
{"Name": "HolisticBias", "Description": "A bias and toxicity benchmark using templated sentences, covering nearly 600 descriptor terms across 13 different demographic axes, for a total of 450k examples", "Modalities": ["Text"], "Categories": ["Model Evaluation: Risks & Harms"], "Date": "10-2022", "Primary Link": "GitHub", "Paper Link": "https://arxiv.org/abs/2205.09209", "Website Link": "https://ai.meta.com/research/publications/im-sorry-to-hear-that-finding-new-biases-in-language-models-with-a-holistic-descriptor-dataset/", "GitHub Link": "https://github.com/facebookresearch/ResponsibleNLP/tree/main/holistic_bias", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Purple Llama CyberSecEval", "Description": "A benchmark for coding assistants, measuring their propensity to generate insecure code and level of compliance when asked to assist in cyberattacks.", "Modalities": ["Text"], "Categories": ["Model Evaluation: Risks & Harms"], "Date": "12-2023", "Primary Link": "Webpage", "Paper Link": "", "Website Link": "https://ai.meta.com/research/publications/purple-llama-cyberseceval-a-benchmark-for-evaluating-the-cybersecurity-risks-of-large-language-models/", "GitHub Link": "https://github.com/facebookresearch/PurpleLlama/tree/main/CybersecurityBenchmarks", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Purple Llama Guard", "Description": "A tool to identify and protect against malicious inputs to LLMs.", "Modalities": ["Text"], "Categories": ["Model Evaluation: Risks & Harms"], "Date": "12-2023", "Primary Link": "Webpage", "Paper Link": "https://arxiv.org/abs/2312.06674", "Website Link": "https://ai.meta.com/research/publications/llama-guard-llm-based-input-output-safeguard-for-human-ai-conversations/", "GitHub Link": "https://github.com/facebookresearch/PurpleLlama/tree/main/Llama-Guard", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Racial disparities in automated speech recognition", "Description": "A discussion of racial disparities and inclusiveness in automated speech recognition.", "Modalities": ["Speech"], "Categories": ["Model Evaluation: Risks & Harms"], "Date": "3-2020", "Primary Link": "Paper", "Paper Link": "", "Website Link": "https://www.pnas.org/doi/10.1073/pnas.1915768117", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "RealToxicityPrompts", "Description": "A dataset of 100k sentence snippets from the web for researchers to further address the risk of neural toxic degeneration in models.", "Modalities": ["Text"], "Categories": ["Model Evaluation: Risks & Harms"], "Date": "9-2020", "Primary Link": "GitHub", "Paper Link": "https://arxiv.org/abs/2009.11462", "Website Link": "https://toxicdegeneration.allenai.org/", "GitHub Link": "https://github.com/allenai/real-toxicity-prompts", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Red Teaming LMs with LMs", "Description": "A method for using one language model to automatically find cases where a target LM behaves in a harmful way, by generating test cases (\"red teaming\")", "Modalities": ["Text"], "Categories": ["Model Evaluation: Risks & Harms"], "Date": "2-2022", "Primary Link": "Paper", "Paper Link": "https://arxiv.org/abs/2202.03286", "Website Link": "", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Safety evaluation repository", "Description": "A repository of safety evaluations, across all modalities and harms, as of late 2023. Useful for delving deeper if the following evaluations don't meet your needs.", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Model Evaluation: Risks & Harms"], "Date": "10-2023", "Primary Link": "Webpage", "Paper Link": "", "Website Link": "https://dpmd.ai/46CPd58", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "SimpleSafetyTests", "Description": "Small probe set (100 English text prompts) covering severe harms: child abuse, suicide, self-harm and eating disorders, scams and fraud, illegal items, and physical harm", "Modalities": ["Text"], "Categories": ["Model Evaluation: Risks & Harms"], "Date": "11-2023", "Primary Link": "GitHub", "Paper Link": "https://arxiv.org/abs/2311.08370", "Website Link": "", "GitHub Link": "https://github.com/bertiev/SimpleSafetyTests", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "SneakyPrompt", "Description": "Automated jailbreaking method to generate NSFW content even with models that have filters applied", "Modalities": ["Vision"], "Categories": ["Model Evaluation: Risks & Harms"], "Date": "5-2023", "Primary Link": "GitHub", "Paper Link": "https://arxiv.org/abs/2305.12082", "Website Link": "", "GitHub Link": "https://github.com/Yuchen413/text2image_safety", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "StableBias", "Description": "Bias testing benchmark for Image to Text models, based on gender-occupation associations.", "Modalities": ["Vision"], "Categories": ["Model Evaluation: Risks & Harms"], "Date": "3-2023", "Primary Link": "Hugging Face object", "Paper Link": "", "Website Link": "https://arxiv.org/abs/2303.11408", "GitHub Link": "", "HuggingFace Link": "https://huggingface.co/spaces/society-ethics/StableBias", "Added By": "Original Authors"}
{"Name": "Cerebras Model Lab", "Description": "A calculator to apply compute-optimal scaling laws for a given budget, including factoring expected total inference usage.", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Model Training: Efficiency & Resource Allocation"], "Date": "5-2023", "Primary Link": "Webpage", "Paper Link": "", "Website Link": "https://www.cerebras.net/model-lab/", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "QLoRa", "Description": "An efficient finetuning approach that reduces memory usage while training.", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Model Training: Efficiency & Resource Allocation"], "Date": "5-2023", "Primary Link": "Paper", "Paper Link": "https://arxiv.org/abs/2305.14314", "Website Link": "", "GitHub Link": "https://github.com/artidoro/qlora", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Scaling Data-Constrained Language Models", "Description": "Demonstrates an optimal allocation of compute when dataset size is bounded", "Modalities": ["Text"], "Categories": ["Model Training: Efficiency & Resource Allocation"], "Date": "5-2023", "Primary Link": "Paper", "Paper Link": "https://arxiv.org/abs/2305.16264", "Website Link": "", "GitHub Link": "https://github.com/huggingface/datablations", "HuggingFace Link": "https://huggingface.co/datablations", "Added By": "Original Authors"}
{"Name": "Training Compute-Optimal Language Models", "Description": "Proposes an optimal allocation of computational budget between model and dataset size, and shows experimental design for fitting scaling laws for compute allocation in a new setting.", "Modalities": ["Text"], "Categories": ["Model Training: Efficiency & Resource Allocation"], "Date": "3-2022", "Primary Link": "Paper", "Paper Link": "https://arxiv.org/abs/2203.15556", "Website Link": "", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "AI Incident Database", "Description": "A database of harmful incidents tied to AI systems where developers or users can submit incident reports", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Usage Monitoring"], "Date": "Frequently Updated", "Primary Link": "Webpage", "Paper Link": "", "Website Link": "https://incidentdatabase.ai/", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "BigScience Ethical Charter", "Description": "Outlines BigScience's core values and how they promote them, which in turn guides use restrictions and communicates acceptable usage to users", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Usage Monitoring"], "Date": "6-2022", "Primary Link": "Webpage", "Paper Link": "", "Website Link": "https://bigscience.huggingface.co/blog/bigscience-ethical-charter", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Llama 2 Responsible Use Guide", "Description": "Guidance for downstream developers on how to responsibly build with Llama 2. Includes details on how to report issues and instructions related to red-teaming and RLHF", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Usage Monitoring"], "Date": "12-2023", "Primary Link": "Webpage", "Paper Link": "", "Website Link": "https://ai.meta.com/llama/responsible-use-guide/", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Model Gating from Hugging Face", "Description": "A resource describing how to require user credentials for model access, which may be appropriate for models trained for topics such as hate speech", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Usage Monitoring"], "Date": "Frequently Updated", "Primary Link": "Webpage", "Paper Link": "", "Website Link": "https://huggingface.co/docs/hub/models-gated", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Model Monitoring in Practice Tutorial", "Description": "A tutorial given at FAccT and other venues describing how and why to monitor ML models. Includes a presentation on using transformer models to monitor for error detection", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Usage Monitoring"], "Date": "6-2022", "Primary Link": "Webpage", "Paper Link": "", "Website Link": "https://sites.google.com/view/model-monitoring-tutorial", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Robust Invisible Video Watermarking with Attention", "Description": "A widely used watermark for video models ", "Modalities": ["Vision"], "Categories": ["Usage Monitoring"], "Date": "9-2029", "Primary Link": "Paper", "Paper Link": "https://arxiv.org/abs/1909.01285", "Website Link": "", "GitHub Link": "https://github.com/DAI-Lab/RivaGAN", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Robust Distortion-free Watermarks for Language Models", "Description": "A watermark for autoregressive language models", "Modalities": ["Text"], "Categories": ["Usage Monitoring"], "Date": "7-2023", "Primary Link": "Paper", "Paper Link": "https://arxiv.org/abs/2307.15593", "Website Link": "", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "A Holistic Approach to Undesired Content Detection in the Real World", "Description": "Description of five primary categories (Sexual, Hateful, Violent, Self-harm, Harassment) with sub-categories (e.g. Sexual / sexual content involving minors). Also describes a moderation filter (the OpenAI moderation endpoint), and releases a dataset labelled for the categories.", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Model Evaluation: Risks & Harms Taxonomies"], "Date": "2-2023", "Primary Link": "Paper", "Paper Link": "https://arxiv.org/pdf/2208.03274.pdf", "Website Link": "", "GitHub Link": "https://github.com/openai/moderation-api-release", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Perspective API", "Description": "Perspective API for content moderation. It has three classes of categories, each with 6+ attributes. (1) Production (Toxicity, Severe Toxicity, Identity Attack, Insult, Profanity, and Threats), (2) Experimental (Toxicity, Severe Toxicity, Identity Attack, Insult, Profanity, Threat, Sexually Explicit, and Flirtation), (3) NY Times (Attack on author, Attack on commenter, Incoherent, Inflammatory, Likely to Reject, Obscene, Spam, Unsubstantial).", "Modalities": ["Text"], "Categories": ["Model Evaluation: Risks & Harms"], "Date": "8-2022", "Primary Link": "Paper", "Paper Link": "https://dl.acm.org/doi/pdf/10.1145/3534678.3539147", "Website Link": "https://developers.perspectiveapi.com/s/about-the-api-attributes-and-languages?language=en_US", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Mistral in-context self-reflection safety prompt", "Description": "Self-reflection prompt for use as a content moderation filter. It returns a binary value (safe/not) with 13 subcategories: Illegal, Child abuse, Hate Violence Harassment, Malware, Physical Harm, Economic Harm, Fraud, Adult, Political campaigning or lobbying, Privacy invasion, Unqualified law advice, Unqualified financial advice, Unqualified health advice", "Modalities": ["Text"], "Categories": ["Model Evaluation: Risks & Harms"], "Date": "10-2023", "Primary Link": "Paper", "Paper Link": "https://arxiv.org/pdf/2310.06825.pdf", "Website Link": "https://www.promptingguide.ai/models/mistral-7b", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Google, Gemini API Safety Filters (via Vertex)", "Description": "Safety filter for Gemini models, available through Vertex. 4 safety attributes are described: Hate speech, Harassment, Sexually Explicit, and Dangerous Content. Probabilities are returned for each attribute (Negligible, Low, Medium, High). ", "Modalities": ["Text"], "Categories": ["Model Evaluation: Risks & Harms"], "Date": "12-2023", "Primary Link": "Webpage", "Paper Link": "", "Website Link": "https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/configure-safety-attributes", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Google, PaLM API Safety Filters (via Vertex)", "Description": "Safety filter for PaLM models, available through Vertex. 16 safety attributes are described (some of which are 'topical' rather than purely safety risks): Derogatory, Toxic, Violent, Sexual, Insult, Profanity, Death Harm & Tragedy, Firearms & Weapons, Public safety, Health, Religion & belief, Illicit drugs, War & conflict, Politics, Finance, Legal.", "Modalities": ["Text"], "Categories": ["Model Evaluation: Risks & Harms"], "Date": "3-2023", "Primary Link": "Webpage", "Paper Link": "", "Website Link": "https://cloud.google.com/vertex-ai/docs/generative-ai/configure-safety-attributes-palm", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "ActiveFence's LLM Safety Review: Benchmarks and Analysis", "Description": "Description of 4 risk categories, as part of a benchmark review of LLM safety: (1) Hate, (2) Misinformation, (3) Self-harm & Suicide, (4) Child abuse & exploitation.", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Model Evaluation: Risks & Harms Taxonomies"], "Date": "07-2023", "Primary Link": "Paper", "Paper Link": "https://www.activefence.com/LLMSafety", "Website Link": "", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Anthropic content moderation prompt", "Description": "In-context prompt for assessing whether messages and responses contain inappropriate content: \"violent, illegal or pornographic activities\"", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Model Evaluation: Risks & Harms"], "Date": "12-2023", "Primary Link": "Webpage", "Paper Link": "", "Website Link": "https://docs.anthropic.com/claude/docs/content-moderation", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Red Teaming Language Models to Reduce Harms: Methods, Scaling Behaviors, and Lessons Learned", "Description": "Description of 20 risk areas, as part of red teaming Anthropics' models. Two of the tags are not interpretable (\"Other\" and \"N/A - Invalid attempt\"): Discrimination & justice, Hate speech & offensive language, Violence & incitement, Non-violent unethical behaviour (e.g. lying, cheating), Bullying & harassment, Other, Theft, N/A - Invalid attempt, Soliciting personally identifiable information, Conspiracy theories & misinformation, Substance abuse & banned substances, Fraud & deception, Weapons, Adult content, Property crime & vandalism, Animal abuse, Terrorism & organized crime, Sexual exploitation & human trafficking, Self-harm, Child abuse.", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Model Evaluation: Risks & Harms Taxonomies"], "Date": "10-2022", "Primary Link": "Paper", "Paper Link": "https://arxiv.org/pdf/2209.07858.pdf", "Website Link": "", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "BEAVERTAILS: Towards Improved Safety Alignment of LLM via a Human-Preference Dataset", "Description": "Description of 14 risk areas, as part of a QA dataset for aligning models and evaluating their safety: Hate Speech, Offensive Language, Discrimination, Stereotype, Injustice, Violence, Aiding and Abetting, Incitement, Financial Crime, Property Crime, Theft, Privacy Violation, Drug Abuse, Weapons, Banned Substance, Non-Violent Unethical Behavior, Sexually Explicit, Adult Content, Controversial Topics, Politics, Misinformation Re. ethics, laws and safety, Terrorism, Organized Crime, Self-Harm, Animal Abuse, Child Abuse", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Model Evaluation: Risks & Harms Taxonomies"], "Date": "10-2023", "Primary Link": "Paper", "Paper Link": "https://arxiv.org/pdf/2307.04657.pdf", "Website Link": "", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Safety Assessment of Chinese Large Language Models", "Description": "Description of 8 risk areas (called \"safety scenarios)\": Insult, Unfairness and Discrimination, Crimes and Illegal Activities, Sensitive Topics, Physical Harm, Mental health, Privacy and Property, Ethics and Morality. Six \"instruction attacks\" are also described: Goal hijacking, Prompt leaking, RolePlay Instruction, Unsafe Instruction Topic, Inquiry with Unsafe Opinion, Reverse Exposure.", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Model Evaluation: Risks & Harms Taxonomies"], "Date": "4-2023", "Primary Link": "Paper", "Paper Link": "https://arxiv.org/pdf/2304.10436.pdf", "Website Link": "", "GitHub Link": "https://github.com/thu-coai/Safety-Prompts", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "DECODINGTRUST: A Comprehensive Assessment of Trustworthiness in GPT Models", "Description": "Description of 8 evaluation areas: toxicity, stereotypes bias, adversarial robustness, out-of-distribution robustness, robustness against adversarial demonstrations, privacy, machine ethics, fairness.", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Model Evaluation: Risks & Harms Taxonomies"], "Date": "1-2024", "Primary Link": "Paper", "Paper Link": "https://arxiv.org/pdf/2306.11698.pdf", "Website Link": "", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "A Unified Typology of Harmful Content", "Description": "Taxonomy of harmful online content. There are 4 primary categories, which each have subcategories: (1) Hate and harassment (Doxxing, Identity attack, Identity misrepresentation, Insult, Sexual aggression, Threat of violence; (2) Self-inflicted harm (Eating disorder promotion, self-harm), (3) Ideological harm (Extremism Terrorism & Organized crime, Misinformation), (4) Exploitation (Adult sexual services, Child sexual abuse material, Scams).", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Model Evaluation: Risks & Harms Taxonomies"], "Date": "Taxonomy of harmful online content. There are 4 primary categories, which each have subcategories: (1) Hate and harassment (Doxxing, Identity attack, Identity misrepresentation, Insult, Sexual aggression, Threat of violence; (2) Self-inflicted harm (Eating disorder promotion, self-harm), (3) Ideological harm (Extremism Terrorism & Organized crime, Misinformation), (4) Exploitation (Adult sexual services, Child sexual abuse material, Scams).", "Primary Link": "Paper", "Paper Link": "https://aclanthology.org/2020.alw-1.16.pdf", "Website Link": "https://docs.cohere.com/docs/content-moderation-with-classify", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Towards Safer Generative Language Models: A Survey on Safety Risks, Evaluations, and Improvements", "Description": "Description of 7 risk areas, as part of a survey on LLM risks: Toxicity and Abusive Content, Unfairness and Discrimination, Ethics and Morality Issues, Controversial Opinions, Misleading Information, Privacy and Data Leakage, Malicious Use and Unleashing AI Agents.", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Model Evaluation: Risks & Harms Taxonomies"], "Date": "11-2023", "Primary Link": "Paper", "Paper Link": "https://arxiv.org/pdf/2302.09270.pdf", "Website Link": "", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Llama 2: Open Foundation and Fine-Tuned Chat Models", "Description": "Description of 3 risk areas, as part of the safety checks for releasing Llama2: (1) illicit and criminal activities (terrorism, theft, huam trafficking), (2) hateful and harmful activities (defamation, self-harm, eating disorders, discrimination), and (3) unqualified advice (medical, financial and legal advice). Other risk categories are described as part of red teaming and soliciting feedback.", "Modalities": ["Text"], "Categories": ["Model Evaluation: Risks & Harms Taxonomies"], "Date": "7-2023", "Primary Link": "Paper", "Paper Link": "https://arxiv.org/pdf/2307.09288.pdf", "Website Link": "", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Ethical and social risks of harm from Language Models", "Description": "Two-tier taxonomy of risks, comprising both classification groups (of which there are 6) and associated harms (3 or 4 for each classification group). The classification groups are: (1) Discrimination, Exclusion and Toxicity, (2) Information Hazards, (3) Misinformation Harms, (4) Malicious Uses, (5) Human-Computer Interaction Harms, and (6) Automation, access, and environmental harms.", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Model Evaluation: Risks & Harms Taxonomies"], "Date": "12-2021", "Primary Link": "Paper", "Paper Link": "https://arxiv.org/pdf/2112.04359.pdf", "Website Link": "", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Sociotechnical Safety Evaluation of Generative AI Systems", "Description": "Two-tier taxonomy of risks, comprising both classification groups (of which there are 6) and associated harms (3 or 4 for each classification group). The classification groups are: (1) Representation and Toxicity Harms, (2) Misinformation Harms, (3) Information & Society Harms, (4) Malicious Use, (5) Human Autonomy & Integrity Harms, and (6) Socioeconomic & Environmental Harms.", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Model Evaluation: Risks & Harms Taxonomies"], "Date": "10-2023", "Primary Link": "Paper", "Paper Link": "https://arxiv.org/pdf/2310.11986.pdf", "Website Link": "", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Trustworthy LLMs: a Survey and Guideline for Evaluating Large Language Models' Alignment", "Description": "Two-tier taxonomy of risks, with seven major categories of LLM trustworthiness, each of which has several associated sub-categories: (1) Reliability, (2) Safety, (3) Fairness, (4) Resistance to Misuse, (5) Explainability and Reasoning, (6) Social Norms, and (7) Robustness.", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Model Evaluation: Risks & Harms Taxonomies"], "Date": "8-2023", "Primary Link": "Paper", "Paper Link": "https://arxiv.org/pdf/2308.05374.pdf", "Website Link": "", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Process for Adapting Language Models to Society (PALMS) with Values-Targeted Datasets", "Description": "Description of 8 risk areas, as part of describing methods for aligning models: (1) Abuse, Violence and Threat (inclusive of self-harm), (2) Health (phyiscal and mental), (3) Human characteristics and behaviour, (4) Injustice and inequality (incl, discrimination, harmful stereotypes), (5) Political opinion and destabilization, (6) Relationships (romantic, familial friendships), (7) Sexual activity (inclusive of pornography), (8) Terrorism (inclusive of white supremacy).", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Model Evaluation: Risks & Harms Taxonomies"], "Date": "6-2021", "Primary Link": "Paper", "Paper Link": "https://arxiv.org/pdf/2106.10328.pdf", "Website Link": "", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Sociotechnical Harms of Algorithmic Systems: Scoping a Taxonomy for Harm Reduction", "Description": "Description of 5 categories of harm, with detailed subcategories: (1) Representational harms, (2) Allocative harms, (3) Quality of Service harms, (4) Interpersonal harms, and (5) Social system harms. ", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Model Evaluation: Risks & Harms Taxonomies"], "Date": "7-2023", "Primary Link": "Paper", "Paper Link": "https://arxiv.org/pdf/2210.05791.pdf", "Website Link": "", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Deepfakes, Phrenology, Surveillance, and More! A Taxonomy of AI Privacy Risks", "Description": "Taxonomy of 12 privacy risks, based on reviewing 321 privacy-related incidents, filtered from the AI, Algorithmic and Automation Incident and Controversy Repository (AIAAIC) Database. Risks are split into those that are created by AI (Identification, Distortion, Exposure, Aggregation, Phrenology/Physiognomy) and those that are exacerbated by AI (Intrusion, Surveillance, Exclusion, Secondary Use, Insecurity, Increased Accessibility).", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Model Evaluation: Risks & Harms Taxonomies"], "Date": "10-2023", "Primary Link": "Paper", "Paper Link": "https://arxiv.org/pdf/2310.07879.pdf", "Website Link": "", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "The Ethical Implications of Generative Audio Models: A Systematic Literature Review", "Description": "Taxonomy of 12 \"negative broader impacts\" from generative models involving speech and music.", "Modalities": ["Speech"], "Categories": ["Model Evaluation: Risks & Harms Taxonomies"], "Date": "7-2023", "Primary Link": "Paper", "Paper Link": "https://arxiv.org/pdf/2307.05527.pdf", "Website Link": "", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "An Overview of Catastrophic AI Risks", "Description": "Taxonomy of 4 catastrophic AI risks, with subcategories: (1) Malicious use (Bioterrrorism, Uncontrolled AI agents, AI capabilities for propaganda, Censorship and surveillance), (2) AI race (Autonomous weapons,  Cyberwarfare, Automated human labour [mass unemployment and dependence on AI systems], (3) Organizational risks (AI accidentally leaked/stolen), (4) Rogue AIs (Proxy gaming, Goal drift, Power-seeking, Deception).", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Model Evaluation: Risks & Harms Taxonomies"], "Date": "9-2023", "Primary Link": "Paper", "Paper Link": "https://arxiv.org/pdf/2306.12001.pdf", "Website Link": "", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "The Malicious Use of Artificial Intelligence: Forecasting, Prevention, and Mitigation", "Description": "Taxonomy of 3 AI security risks, with subcategories: (1) Digital Security, Physical Security, Political Security.", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Model Evaluation: Risks & Harms Taxonomies"], "Date": "2-2018", "Primary Link": "Paper", "Paper Link": "https://img1.wsimg.com/blobby/go/3d82daa4-97fe-4096-9c6b-376b92c619de/downloads/MaliciousUseofAI.pdf?ver=1553030594217", "Website Link": "", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Open-sourcing highly capable foundation models", "Description": "Description of risks from malicious use of AI: Influence operations, Surveillance and population control, Scamming and spear phishing, Cyber attacks, Biological and chemical weapons development. Some \"extreme risks\" are also described in the paper (e.g. disruption to key societal functions).", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Model Evaluation: Risks & Harms Taxonomies"], "Date": "9-2023", "Primary Link": "Paper", "Paper Link": "https://cdn.governance.ai/Open-Sourcing_Highly_Capable_Foundation_Models_2023_GovAI.pdf", "Website Link": "", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "How Does Access Impact Risk? Assessing AI Foundation Model Risk Along a Gradient of Access ", "Description": "Description of risks from open-sourcing models, including five instances of malicious use: (1) Fraud and other crime schemes, (2) Undermining of social cohesion and democratic processes, (3) Human rights abuses, (4) Disruption of critical infrastructure, and (5) State conflict. ", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Model Evaluation: Risks & Harms Taxonomies"], "Date": "12-2023", "Primary Link": "Paper", "Paper Link": "https://securityandtechnology.org/wp-content/uploads/2023/12/How-Does-Access-Impact-Risk-Assessing-AI-Foundation-Model-Risk-Along-A-Gradient-of-Access-Dec-2023.pdf", "Website Link": "", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "OpenAI Preparedness Framework (Beta)", "Description": "Description of 4 catastrophic AI risks: (1) Cybersecurity, (2) Chemical, Biological, Nuclear and Radiological (CBRN) threats, (3) Persuasion, and (4) Model autonomy. The paper also highlights the risk of \"unknown unknowns\".", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Model Evaluation: Risks & Harms Taxonomies"], "Date": "12-2023", "Primary Link": "Paper", "Paper Link": "https://cdn.openai.com/openai-preparedness-framework-beta.pdf", "Website Link": "", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Anthropic's Responsible Scaling Policy", "Description": "Framework with four tiers of model capability, ffrom ASL-1 (smaller models) to ASL-4 (speculative), with increasing risk as models' capability increases. It also describes 4 catastrophic AI risks: (1) Misuse risks, (2) CBRN risks, (3) Cyber risks, and (4) Autonomy and replication risks.", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Model Evaluation: Risks & Harms Taxonomies"], "Date": "9-2023", "Primary Link": "Paper", "Paper Link": "https://www-files.anthropic.com/production/files/responsible-scaling-policy-1.0.pdf", "Website Link": "", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Model evaluation for extreme risks", "Description": "Framework of 9 dangerous capabilities of AI models: (1) Cyber-offense, (2) Deception, (3) Persuasion & manipulation, (4) Politial strategy, (5) Weapons acquisition, (6) Long-horizon planning, (7) AI development, (8) Situational awareness, (9) Self-proliferation.", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Model Evaluation: Risks & Harms Taxonomies"], "Date": "9-2023", "Primary Link": "Paper", "Paper Link": "https://arxiv.org/pdf/2305.15324.pdf", "Website Link": "", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Frontier AI Regulation: Managing Emerging Risks to Public Safety", "Description": "Description of \"sufficiently dangerous capabilities\" of AI models to cause serious harm and disruption on a global scale, such as synthesing new biological or chemical weapons and evading human control through means of deception and obfuscation.", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Model Evaluation: Risks & Harms Taxonomies"], "Date": "11-2023", "Primary Link": "Paper", "Paper Link": "https://arxiv.org/pdf/2307.03718.pdf", "Website Link": "", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "The Fallacy of AI Functionality", "Description": "Taxonomy of four AI failure points: (1) Impossible tasks (either Conceptually impossible or Practically impossible), (2) Engineering failures (Design failures, Implementation failures, Missing Safety Features), (3) Post-Deployment Failures (Robustness Issues, Failure under Adversarial Attacks, Unanticipated Intractions, (4) Communication Failures (Falsified or Overstated Capabilities, Misrepresented Capabilities).", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Model Evaluation: Risks & Harms Taxonomies"], "Date": "7-2022", "Primary Link": "Paper", "Paper Link": "https://arxiv.org/pdf/2206.09511.pdf", "Website Link": "", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "TASRA: a Taxonomy and Analysis of Societal-Scale Risks from AI", "Description": "Framework of 3 potential harms from AI: (1) Harm to people (individual harm, Group/community harm, Societal harm), (2) Harm to an Organisation or Enterprise, (3) Harm to a system. ", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Model Evaluation: Risks & Harms Taxonomies"], "Date": "6-2023", "Primary Link": "Paper", "Paper Link": "https://arxiv.org/pdf/2306.06924.pdf", "Website Link": "", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Cohere in-context content moderation prompt", "Description": "Few-shot prompt for classifying whether text is toxic or not.", "Modalities": ["Text"], "Categories": ["Model Evaluation: Risks & Harms"], "Date": "12-2023", "Primary Link": "Webpage", "Paper Link": "", "Website Link": "https://docs.cohere.com/reference/toxicity-detection", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "NVidia NeMo Guardrails", "Description": "Open-source tooling to create guardrails for LLM applications.", "Modalities": ["Text"], "Categories": ["Model Evaluation: Risks & Harms"], "Date": "4-2023", "Primary Link": "Paper", "Paper Link": "https://arxiv.org/pdf/2310.10501.pdf", "Website Link": "https://blogs.nvidia.com/blog/ai-chatbot-guardrails-nemo/", "GitHub Link": "https://github.com/NVIDIA/NeMo-Guardrails", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "SafetyPrompts", "Description": "Open repository of datasets for LLM safety", "Modalities": ["Text"], "Categories": ["Model Evaluation: Risks & Harms"], "Date": "1-2024", "Primary Link": "Webpage", "Paper Link": "", "Website Link": "https://safetyprompts.com/", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Model Risk Cards", "Description": "A framework for structured assessment and documentation of risks associated with an application of language models. Each RiskCard makes clear the routes for the risk to manifest harm, their placement in harm taxonomies, and example prompt-output pairs. The paper also describes 70+ risks identified from a literature survey.", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Model Evaluation: Risks & Harms"], "Date": "3-2023", "Primary Link": "Paper", "Paper Link": "https://arxiv.org/pdf/2303.18190.pdf", "Website Link": "", "GitHub Link": "https://github.com/leondz/lm_risk_cards", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Aya Dataset", "Description": "A permissively licensed multilingual instruction finetuning dataset curated by the Aya Annotation Platform from Cohere For AI. The dataset contains a total of 204k human-annotated prompt-completion pairs along with the demographics data of the annotators, spanning 65 languages.", "Modalities": ["Text"], "Categories": ["Finetuning Data Catalogs"], "Date": "2-2024", "Primary Link": "Webpage", "Paper Link": "https://arxiv.org/abs/2402.06619", "Website Link": "https://cohere.com/research/aya", "GitHub Link": "", "HuggingFace Link": "https://huggingface.co/datasets/CohereForAI/aya_dataset", "Added By": "Original Authors"}
{"Name": "HuggingFace Provenance, Watermarking & Deepfake Detection Collection", "Description": "A collection of resources on provenance, watermarking & deepfake detection tools, that are used to assess the outputs of foundation models.", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Usage Monitoring"], "Date": "2-2024", "Primary Link": "Hugging Face object", "Paper Link": "", "Website Link": "", "GitHub Link": "", "HuggingFace Link": "https://huggingface.co/collections/society-ethics/provenance-watermarking-and-deepfake-detection-65c6792b0831983147bb7578", "Added By": "Original Authors"}
{"Name": "SIB-200", "Description": "A large-scale open-sourced benchmark dataset for topic classification in 200 languages and dialects.", "Modalities": ["Text"], "Categories": ["Model Evaluation: Capabilities"], "Date": "9-2023", "Primary Link": "GitHub", "Paper Link": "https://arxiv.org/abs/2309.07445", "Website Link": "", "GitHub Link": "https://github.com/dadelani/sib-200", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "French-PD-Newpapers", "Description": "Nearly three million unique newspaper and periodical editions (70B words) from the French National Library.", "Modalities": ["Text"], "Categories": ["Pretraining Data Sources"], "Date": "1-2024", "Primary Link": "Hugging Face object", "Paper Link": "", "Website Link": "", "GitHub Link": "", "HuggingFace Link": "https://huggingface.co/datasets/PleIAs/French-PD-Newspapers", "Added By": "Original Authors"}
{"Name": "Datatrove", "Description": "A library to process, filter and deduplicate text data at a very large scale", "Modalities": ["Text"], "Categories": ["Data Cleaning, Filtering, & Mixing"], "Date": "12-2023", "Primary Link": "GitHub", "Paper Link": "", "Website Link": "", "GitHub Link": "https://github.com/huggingface/datatrove", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "Nomic", "Description": "A proprietary service to explore data with embedding maps.", "Modalities": ["Text"], "Categories": ["Data Search, Analysis, & Exploration"], "Date": "Frequently Updated", "Primary Link": "Webpage", "Paper Link": "", "Website Link": "https://home.nomic.ai/", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
{"Name": "AI Vulnerability Database", "Description": "An open-source, extensible knowledge base of AI failures.", "Modalities": ["Text", "Speech", "Vision"], "Categories": ["Usage Monitoring"], "Date": "Frequently Updated", "Primary Link": "Webpage", "Paper Link": "", "Website Link": "https://avidml.org/", "GitHub Link": "", "HuggingFace Link": "", "Added By": "Original Authors"}
